<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title></title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inference.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>1</b> Inferencia estadística</a><ul>
<li class="chapter" data-level="1.1" data-path="inference.html"><a href="inference.html#encuestas"><i class="fa fa-check"></i><b>1.1</b> Encuestas</a><ul>
<li class="chapter" data-level="1.1.1" data-path="inference.html"><a href="inference.html#el-modelo-de-muestreo-para-encuestas"><i class="fa fa-check"></i><b>1.1.1</b> El modelo de muestreo para encuestas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="inference.html"><a href="inference.html#poblaciones-muestras-parametros-y-estimaciones"><i class="fa fa-check"></i><b>1.2</b> Poblaciones, muestras, parámetros y estimaciones</a><ul>
<li class="chapter" data-level="1.2.1" data-path="inference.html"><a href="inference.html#el-promedio-de-la-muestra"><i class="fa fa-check"></i><b>1.2.1</b> El promedio de la muestra</a></li>
<li class="chapter" data-level="1.2.2" data-path="inference.html"><a href="inference.html#parameters"><i class="fa fa-check"></i><b>1.2.2</b> Parameters</a></li>
<li class="chapter" data-level="1.2.3" data-path="inference.html"><a href="inference.html#polling-versus-forecasting"><i class="fa fa-check"></i><b>1.2.3</b> Polling versus forecasting</a></li>
<li class="chapter" data-level="1.2.4" data-path="inference.html"><a href="inference.html#properties-of-our-estimate-expected-value-and-standard-error"><i class="fa fa-check"></i><b>1.2.4</b> Properties of our estimate: expected value and standard error</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="inference.html"><a href="inference.html#ejercicios"><i class="fa fa-check"></i><b>1.3</b> Ejercicios</a></li>
<li class="chapter" data-level="1.4" data-path="inference.html"><a href="inference.html#clt"><i class="fa fa-check"></i><b>1.4</b> Teorema del límite central en la práctica</a><ul>
<li class="chapter" data-level="1.4.1" data-path="inference.html"><a href="inference.html#una-simulacion-de-monte-carlo"><i class="fa fa-check"></i><b>1.4.1</b> Una simulación de Monte Carlo</a></li>
<li class="chapter" data-level="1.4.2" data-path="inference.html"><a href="inference.html#la-propagacion"><i class="fa fa-check"></i><b>1.4.2</b> La propagación</a></li>
<li class="chapter" data-level="1.4.3" data-path="inference.html"><a href="inference.html#sesgo-por-que-no-realizar-una-encuesta-muy-grande"><i class="fa fa-check"></i><b>1.4.3</b> Sesgo: ¿por qué no realizar una encuesta muy grande?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="inference.html"><a href="inference.html#ejercicios-1"><i class="fa fa-check"></i><b>1.5</b> Ejercicios</a></li>
<li class="chapter" data-level="1.6" data-path="inference.html"><a href="inference.html#intervalos-de-confianza"><i class="fa fa-check"></i><b>1.6</b> Intervalos de confianza</a><ul>
<li class="chapter" data-level="1.6.1" data-path="inference.html"><a href="inference.html#una-simulacion-de-monte-carlo-1"><i class="fa fa-check"></i><b>1.6.1</b> Una simulación de Monte Carlo</a></li>
<li class="chapter" data-level="1.6.2" data-path="inference.html"><a href="inference.html#el-idioma-correcto"><i class="fa fa-check"></i><b>1.6.2</b> El idioma correcto</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="inference.html"><a href="inference.html#ejercicios-2"><i class="fa fa-check"></i><b>1.7</b> Ejercicios</a></li>
<li class="chapter" data-level="1.8" data-path="inference.html"><a href="inference.html#poder"><i class="fa fa-check"></i><b>1.8</b> Poder</a></li>
<li class="chapter" data-level="1.9" data-path="inference.html"><a href="inference.html#valores-p"><i class="fa fa-check"></i><b>1.9</b> valores p</a></li>
<li class="chapter" data-level="1.10" data-path="inference.html"><a href="inference.html#association-tests"><i class="fa fa-check"></i><b>1.10</b> Pruebas de asociación</a><ul>
<li class="chapter" data-level="1.10.1" data-path="inference.html"><a href="inference.html#lady-tasting-tea"><i class="fa fa-check"></i><b>1.10.1</b> Lady Tasting Tea</a></li>
<li class="chapter" data-level="1.10.2" data-path="inference.html"><a href="inference.html#tablas-de-dos-en-dos"><i class="fa fa-check"></i><b>1.10.2</b> Tablas de dos en dos</a></li>
<li class="chapter" data-level="1.10.3" data-path="inference.html"><a href="inference.html#prueba-de-chi-cuadrado"><i class="fa fa-check"></i><b>1.10.3</b> Prueba de chi-cuadrado</a></li>
<li class="chapter" data-level="1.10.4" data-path="inference.html"><a href="inference.html#odds-ratio"><i class="fa fa-check"></i><b>1.10.4</b> La razón de posibilidades</a></li>
<li class="chapter" data-level="1.10.5" data-path="inference.html"><a href="inference.html#intervalos-de-confianza-para-la-razon-de-posibilidades"><i class="fa fa-check"></i><b>1.10.5</b> Intervalos de confianza para la razón de posibilidades</a></li>
<li class="chapter" data-level="1.10.6" data-path="inference.html"><a href="inference.html#correccion-de-recuento-pequeno"><i class="fa fa-check"></i><b>1.10.6</b> Corrección de recuento pequeño</a></li>
<li class="chapter" data-level="1.10.7" data-path="inference.html"><a href="inference.html#muestras-grandes-valores-p-pequenos"><i class="fa fa-check"></i><b>1.10.7</b> Muestras grandes, valores p pequeños</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="inference.html"><a href="inference.html#ejercicios-3"><i class="fa fa-check"></i><b>1.11</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i><b>2</b> Modelos estadísticos</a><ul>
<li class="chapter" data-level="2.1" data-path="models.html"><a href="models.html#agregadores-de-encuestas"><i class="fa fa-check"></i><b>2.1</b> Agregadores de encuestas</a><ul>
<li class="chapter" data-level="2.1.1" data-path="models.html"><a href="models.html#datos-de-encuesta"><i class="fa fa-check"></i><b>2.1.1</b> Datos de encuesta</a></li>
<li class="chapter" data-level="2.1.2" data-path="models.html"><a href="models.html#sesgo-de-encuestador"><i class="fa fa-check"></i><b>2.1.2</b> Sesgo de encuestador</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="models.html"><a href="models.html#data-driven-model"><i class="fa fa-check"></i><b>2.2</b> Modelos basados en datos</a></li>
<li class="chapter" data-level="2.3" data-path="models.html"><a href="models.html#ejercicios-4"><i class="fa fa-check"></i><b>2.3</b> Ejercicios</a></li>
<li class="chapter" data-level="2.4" data-path="models.html"><a href="models.html#bayesian-statistics"><i class="fa fa-check"></i><b>2.4</b> Estadísticas bayesianas</a><ul>
<li class="chapter" data-level="2.4.1" data-path="models.html"><a href="models.html#teorema-de-bayes"><i class="fa fa-check"></i><b>2.4.1</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="models.html"><a href="models.html#simulacion-del-teorema-de-bayes"><i class="fa fa-check"></i><b>2.5</b> Simulación del teorema de Bayes</a><ul>
<li class="chapter" data-level="2.5.1" data-path="models.html"><a href="models.html#bayes-en-la-practica"><i class="fa fa-check"></i><b>2.5.1</b> Bayes en la práctica</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="models.html"><a href="models.html#modelos-jerarquicos"><i class="fa fa-check"></i><b>2.6</b> Modelos jerárquicos</a></li>
<li class="chapter" data-level="2.7" data-path="models.html"><a href="models.html#ejercicios-5"><i class="fa fa-check"></i><b>2.7</b> Ejercicios</a></li>
<li class="chapter" data-level="2.8" data-path="models.html"><a href="models.html#election-forecasting"><i class="fa fa-check"></i><b>2.8</b> Estudio de caso: pronóstico de elecciones</a><ul>
<li class="chapter" data-level="2.8.1" data-path="models.html"><a href="models.html#bayesian-approach"><i class="fa fa-check"></i><b>2.8.1</b> Enfoque bayesiano</a></li>
<li class="chapter" data-level="2.8.2" data-path="models.html"><a href="models.html#el-sesgo-general"><i class="fa fa-check"></i><b>2.8.2</b> El sesgo general</a></li>
<li class="chapter" data-level="2.8.3" data-path="models.html"><a href="models.html#representaciones-matematicas-de-modelos."><i class="fa fa-check"></i><b>2.8.3</b> Representaciones matemáticas de modelos.</a></li>
<li class="chapter" data-level="2.8.4" data-path="models.html"><a href="models.html#prediciendo-el-colegio-electoral"><i class="fa fa-check"></i><b>2.8.4</b> Prediciendo el colegio electoral</a></li>
<li class="chapter" data-level="2.8.5" data-path="models.html"><a href="models.html#prevision"><i class="fa fa-check"></i><b>2.8.5</b> Previsión</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="models.html"><a href="models.html#ejercicios-6"><i class="fa fa-check"></i><b>2.9</b> Ejercicios</a></li>
<li class="chapter" data-level="2.10" data-path="models.html"><a href="models.html#t-dist"><i class="fa fa-check"></i><b>2.10</b> La distribución t</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="models" class="section level1">
<h1><span class="header-section-number">Capítulo 2</span> Modelos estadísticos</h1>
<p>≫&gt; “Todos los modelos están equivocados, pero algunos son útiles”. –George EP Box El día antes de las elecciones presidenciales de 2008, FiveThirtyEight de Nate Silver declaró que “Barack Obama parece preparado para una victoria electoral decisiva”. Fueron más lejos y predijeron que Obama ganaría las elecciones con 349 votos electorales a 189, y el voto popular por un margen del 6,1%. FiveThirtyEight también adjuntó una declaración probabilística a su predicción alegando que Obama tenía un 91% de posibilidades de ganar las elecciones. Las predicciones fueron bastante precisas ya que, en los resultados finales, Obama ganó el colegio electoral 365 a 173 y el voto popular por una diferencia de 7.2%. Su actuación en las elecciones de 2008 atrajo a FiveThirtyEight a la atención de expertos políticos y personalidades de la televisión. Cuatro años más tarde, la semana antes de las elecciones presidenciales de 2012, Nate Silver de FiveThirtyEight le estaba dando a Obama una probabilidad del 90% de ganar a pesar de que muchos expertos pensaban que los resultados finales estarían más cerca. El comentarista político Joe Scarborough dijo durante su show ^ [<a href="https://www.youtube.com/watch?v=TbKkjm-gheY" class="uri">https://www.youtube.com/watch?v=TbKkjm-gheY</a>]:</p>
<p>≫&gt; Cualquiera que piense que esta carrera es todo menos una sacudida en este momento es un gran ideólogo … son bromas. A lo que Nate Silver respondió a través de Twitter:</p>
<p>≫&gt; Si crees que es una sacudida, apuestemos. Si Obama gana, usted dona $ 1,000 a la Cruz Roja Americana. Si Romney gana, yo lo hago. ¿Acuerdo? En 2016, Silver no estaba tan seguro y le dio a Hillary Clinton solo un 71% de victorias. En contraste, la mayoría de los otros pronosticadores estaban casi seguros de que ella ganaría. Ella perdió. Pero el 71% sigue siendo más del 50%, ¿se equivocó el Sr. Silver? ¿Y qué significa la probabilidad en este contexto de todos modos? ¿Se tiran los dados en alguna parte?</p>
<p>En este capítulo demostraremos cómo <em>agregadores_de_poll</em>, como FiveThirtyEight, recopilaron y combinaron datos informados por diferentes expertos para producir predicciones mejoradas. Introduciremos ideas detrás de los _ modelos estadísticos_, también conocidos como “modelos de probabilidad”, que fueron utilizados por los agregadores de encuestas para mejorar los pronósticos electorales más allá del poder de las encuestas individuales. En este capítulo, motivamos los modelos, basándose en los conceptos de inferencia estadística que aprendimos en el Capítulo@ref (inferencia). Comenzamos con modelos relativamente simples, dándonos cuenta de que el ejercicio real de la ciencia de datos de pronosticar elecciones involucra algunos bastante complejos, que presentamos hacia el final del capítulo en la Sección@ref (predicción electoral).</p>
<div id="agregadores-de-encuestas" class="section level2">
<h2><span class="header-section-number">2.1</span> Agregadores de encuestas</h2>
<p>Como describimos anteriormente, unas semanas antes de las elecciones de 2012, Nate Silver le estaba dando a Obama una probabilidad del 90% de ganar. ¿Cómo tenía tanta confianza el señor Silver? Utilizaremos una simulación de Monte Carlo para ilustrar la idea que el Sr. Silver tuvo y otros no vieron. Para hacer esto, generamos resultados para 12 encuestas realizadas la semana anterior a las elecciones. Imitamos tamaños de muestra de encuestas reales y construimos e informamos intervalos de confianza del 95% para cada una de las 12 encuestas. Guardamos los resultados de esta simulación en un marco de datos y agregamos una columna de ID de encuesta.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(dslabs)
d &lt;-<span class="st"> </span><span class="fl">0.039</span>
Ns &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1298</span>, <span class="dv">533</span>, <span class="dv">1342</span>, <span class="dv">897</span>, <span class="dv">774</span>, <span class="dv">254</span>, <span class="dv">812</span>, <span class="dv">324</span>, <span class="dv">1291</span>, <span class="dv">1056</span>, <span class="dv">2172</span>, <span class="dv">516</span>)
p &lt;-<span class="st"> </span>(d <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="st"> </span><span class="dv">2</span>
polls &lt;-<span class="st"> </span><span class="kw">map_df</span>(Ns, <span class="cf">function</span>(N) {
x &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">size=</span>N, <span class="dt">replace=</span><span class="ot">TRUE</span>, <span class="dt">prob=</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>p, p))
x_hat &lt;-<span class="st"> </span><span class="kw">mean</span>(x)
se_hat &lt;-<span class="st"> </span><span class="kw">sqrt</span>(x_hat <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>x_hat)<span class="op">/</span><span class="st"> </span>N)
<span class="kw">list</span>(<span class="dt">estimate =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span>x_hat <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,
<span class="dt">low =</span> <span class="dv">2</span><span class="op">*</span>(x_hat <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se_hat) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,
<span class="dt">high =</span> <span class="dv">2</span><span class="op">*</span>(x_hat <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se_hat) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,
<span class="dt">sample_size =</span> N)
}) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">poll =</span> <span class="kw">seq_along</span>(Ns))</code></pre></div>
<p>Aquí hay una visualización que muestra los intervalos que los encuestadores habrían informado sobre la diferencia entre Obama y Romney:</p>
<p><img src="libro_files/figure-html/simulated-polls-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>No es sorprendente que las 12 encuestas reporten intervalos de confianza que incluyen el resultado de la noche electoral (línea discontinua). Sin embargo, las 12 encuestas también incluyen 0 (línea negra sólida) también. Por lo tanto, si se les pide una predicción individualmente, los encuestadores tendrían que decir: es una sacudida. A continuación describimos una idea clave que les falta.</p>
<p>Los agregadores de encuestas, como Nate Silver, se dieron cuenta de que al combinar los resultados de diferentes encuestas, podría mejorar enormemente la precisión. Al hacer esto, estamos llevando a cabo una encuesta con un gran tamaño de muestra. Por lo tanto, podemos informar un intervalo de confianza menor del 95% y una predicción más precisa.</p>
<p>Aunque como agregadores no tenemos acceso a los datos de la encuesta sin procesar, podemos usar las matemáticas para reconstruir lo que habríamos obtenido si hubiéramos hecho una encuesta grande con:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(polls<span class="op">$</span>sample_size)
<span class="co">#&gt; [1] 11269</span></code></pre></div>
<p>participantes. Básicamente, construimos una estimación de la propagación, llamémosla <span class="math inline">\(d\)</span>, con un promedio ponderado de la siguiente manera:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d_hat &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">sum</span>(estimate<span class="op">*</span>sample_size)<span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(sample_size)) <span class="op">%&gt;%</span>
<span class="kw">pull</span>(avg)</code></pre></div>
<p>Una vez que tengamos una estimación de <span class="math inline">\(d\)</span>, podemos construir una estimación de la proporción de votos para Obama, que luego podemos usar para estimar el error estándar. Una vez que hacemos esto, vemos que nuestro margen de error es 0.018.</p>
<p>Por lo tanto, podemos predecir que la propagación será 3.1 más o menos 1.8, que no solo incluye el resultado real que finalmente observamos en la noche de las elecciones, sino que está bastante lejos de incluir 0. Una vez que combinamos las 12 encuestas, estamos seguros de que Obama ganará el voto popular.</p>
<p><img src="libro_files/figure-html/confidence-coverage-2008-election-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Por supuesto, esto fue solo una simulación para ilustrar la idea. El ejercicio real de la ciencia de datos de pronosticar elecciones es mucho más complicado e implica modelar. A continuación explicamos cómo los encuestadores ajustan los modelos multinivel a los datos y los utilizan para pronosticar los resultados electorales. En las elecciones presidenciales estadounidenses de 2008 y 2012, Nate Silver utilizó este enfoque para hacer una predicción casi perfecta y silenciar a los expertos.</p>
<p>Desde las elecciones de 2008, otras organizaciones han comenzado su propio grupo de pronóstico de elecciones que, como el de Nate Silver, agrega datos de encuestas y utiliza modelos estadísticos para hacer predicciones. En 2016, los pronosticadores subestimaron las posibilidades de Trump de ganar mucho. El día antes de las elecciones, el <em>New York Times</em> informó ^ [<a href="https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html" class="uri">https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html</a>] las siguientes probabilidades de que Hillary Clinton gane la presidencia:</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
NYT
</th>
<th style="text-align:left;">
538
</th>
<th style="text-align:left;">
HuffPost
</th>
<th style="text-align:left;">
PW
</th>
<th style="text-align:left;">
PEC
</th>
<th style="text-align:left;">
DK
</th>
<th style="text-align:left;">
Cook
</th>
<th style="text-align:left;">
Roth
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Win Prob
</td>
<td style="text-align:left;">
85%
</td>
<td style="text-align:left;">
71%
</td>
<td style="text-align:left;">
98%
</td>
<td style="text-align:left;">
89%
</td>
<td style="text-align:left;">
&gt;99%
</td>
<td style="text-align:left;">
92%
</td>
<td style="text-align:left;">
Lean Dem
</td>
<td style="text-align:left;">
Lean Dem
</td>
</tr>
</tbody>
</table>
<!--(Source: [New York Times](https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html))-->
<p>Por ejemplo, el Consorcio Electoral de Princeton (PEC) le dio a Trump menos del 1% de posibilidades de ganar, mientras que el Huffington Post le dio una probabilidad del 2%. Por el contrario, FiveThirtyEight tenía la probabilidad de que Trump ganara al 29%, más que lanzar dos monedas y obtener dos caras. De hecho, cuatro días antes de las elecciones, FiveThirtyEight publicó un artículo titulado <em>Trump es solo un error de sondeo normal detrás de Clinton</em> ^ [<a href="https://fivethirtyeight.com/features/trump-is-just-a-normal-polling-error-behind-" class="uri">https://fivethirtyeight.com/features/trump-is-just-a-normal-polling-error-behind-</a> Clinton/]. Al comprender los modelos estadísticos y cómo estos pronosticadores los usan, comenzaremos a comprender cómo sucedió esto.</p>
<p>Aunque no es tan interesante como predecir el colegio electoral, para fines ilustrativos comenzaremos analizando las predicciones para el voto popular. FiveThirtyEight predijo una ventaja de 3.6% para Clinton ^ [<a href="https://projects.fivethirtyeight.com/2016-election-forecast/" class="uri">https://projects.fivethirtyeight.com/2016-election-forecast/</a>], incluyó el resultado real de 2.1% (48.2% a 46.1%) en su intervalo, y fue mucho más confía en que Clinton gane las elecciones, dándole una probabilidad del 81.4%. Su predicción se resumió con un cuadro como este:</p>
<p><img src="libro_files/figure-html/fivethirtyeight-densities-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Las áreas coloreadas representan valores con una probabilidad del 80% de incluir el resultado real, según el modelo FiveThirtyEight. <!--(Source: [FiveThirtyEight](https://projects.fivethirtyeight.com/2016-election-forecast/))--></p>
<p>Presentamos datos reales de las elecciones presidenciales de EE. UU. De 2016 para mostrar cómo los modelos están motivados y construidos para producir estas predicciones. Para entender la declaración de “81.4% de probabilidad” necesitamos describir las estadísticas bayesianas, lo que hacemos en las Secciones@ref (estadísticas bayesianas) y@ref (enfoque bayesiano).</p>
<div id="datos-de-encuesta" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Datos de encuesta</h3>
<p>Utilizamos datos de encuestas públicas organizados por FiveThirtyEight para las elecciones presidenciales de 2016. Los datos se incluyen como parte del paquete <strong>dslabs</strong>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(polls_us_election_<span class="dv">2016</span>)</code></pre></div>
<p>La tabla incluye los resultados de las encuestas nacionales, así como las encuestas estatales, tomadas durante el año anterior a la elección. Para este primer ejemplo, filtraremos los datos para incluir encuestas nacionales realizadas durante la semana previa a las elecciones. También eliminamos las encuestas que FiveThirtyEight ha determinado que no son confiables y se calificaron con una “B” o menos. Algunas encuestas no han sido calificadas e incluimos aquellas:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-31&quot;</span> <span class="op">&amp;</span>
(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade)))</code></pre></div>
<p>Agregamos una estimación de spread:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</code></pre></div>
<p>Para este ejemplo, asumiremos que solo hay dos partes y llamaremos <span class="math inline">\(p\)</span> la proporción de votos para Clinton y <span class="math inline">\(1-p\)</span> la proporción que vota por Trump. Estamos interesados en la difusión <span class="math inline">\(2p-1\)</span>. Llamemos al spread <span class="math inline">\(d\)</span> (por diferencia)</p>
<p>Tenemos 49 estimaciones de la propagación. La teoría que aprendimos nos dice que estas estimaciones son una variable aleatoria con una distribución de probabilidad que es aproximadamente normal. El valor esperado es la propagación de la noche de las elecciones. <span class="math inline">\(d\)</span> y el error estándar es $ 2PS Suponiendo que el modelo de urna que describimos anteriormente es bueno, podemos usar esta información para construir un intervalo de confianza basado en los datos agregados. El spread estimado es:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d_hat &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">d_hat =</span> <span class="kw">sum</span>(spread <span class="op">*</span><span class="st"> </span>samplesize)<span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(samplesize)) <span class="op">%&gt;%</span>
<span class="kw">pull</span>(d_hat)</code></pre></div>
<p>y el error estándar es:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p_hat &lt;-<span class="st"> </span>(d_hat<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>
moe &lt;-<span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p_hat <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p_hat)<span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(polls<span class="op">$</span>samplesize))
moe
<span class="co">#&gt; [1] 0.00662</span></code></pre></div>
<p>Entonces informamos una extensión de 1.43% con un margen de error de 0.66%. En la noche de las elecciones, descubrimos que el porcentaje real era 2.1%, que está fuera de un intervalo de confianza del 95%. ¿Que pasó?</p>
<p>Un histograma de los spreads informados muestra un problema:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(spread)) <span class="op">+</span>
<span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">binwidth =</span> .<span class="dv">01</span>)</code></pre></div>
<p><img src="libro_files/figure-html/polls-2016-spread-histogram-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Los datos no parecen estar distribuidos normalmente y el error estándar parece ser mayor que 0.007. La teoría no está funcionando del todo aquí.</p>
</div>
<div id="sesgo-de-encuestador" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Sesgo de encuestador</h3>
<p>Observe que varios encuestadores están involucrados y algunos toman varias encuestas por semana:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="kw">n</span>())
<span class="co">#&gt; # A tibble: 15 x 2</span>
<span class="co">#&gt;   pollster                                                   `n()`</span>
<span class="co">#&gt;   &lt;fct&gt;                                                      &lt;int&gt;</span>
<span class="co">#&gt; 1 ABC News/Washington Post                                       7</span>
<span class="co">#&gt; 2 Angus Reid Global                                              1</span>
<span class="co">#&gt; 3 CBS News/New York Times                                        2</span>
<span class="co">#&gt; 4 Fox News/Anderson Robbins Research/Shaw &amp; Company Research     2</span>
<span class="co">#&gt; 5 IBD/TIPP                                                       8</span>
<span class="co">#&gt; # … with 10 more rows</span></code></pre></div>
<p>Visualicemos los datos de los encuestadores que sondean regularmente:</p>
<p><img src="libro_files/figure-html/pollster-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Esta trama revela un resultado inesperado. Primero, considere que el error estándar predicho por la teoría para cada encuesta:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span>
<span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">6</span>) <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">se =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p_hat <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p_hat)<span class="op">/</span><span class="st"> </span><span class="kw">median</span>(samplesize)))
<span class="co">#&gt; # A tibble: 5 x 2</span>
<span class="co">#&gt;   pollster                     se</span>
<span class="co">#&gt;   &lt;fct&gt;                     &lt;dbl&gt;</span>
<span class="co">#&gt; 1 ABC News/Washington Post 0.0265</span>
<span class="co">#&gt; 2 IBD/TIPP                 0.0333</span>
<span class="co">#&gt; 3 Ipsos                    0.0225</span>
<span class="co">#&gt; 4 The Times-Picayune/Lucid 0.0196</span>
<span class="co">#&gt; 5 USC Dornsife/LA Times    0.0183</span></code></pre></div>
<p>está entre 0.018 y 0.033, lo que está de acuerdo con la variación dentro de la encuesta que vemos. Sin embargo, parece haber diferencias entre las encuestas. Observe, por ejemplo, cómo el encuestador USC Dornsife/ LA Times predice un 4%para Trump, mientras que Ipsos predice un triunfo mayor que 5% para Clinton. La teoría que aprendimos no dice nada acerca de diferentes encuestadores que producen encuestas con diferentes valores esperados. Todas las encuestas deben tener el mismo valor esperado. FiveThirtyEight se refiere a estas diferencias como “efectos domésticos”. También los llamamos sesgo de encuestador.</p>
<p>En la siguiente sección, en lugar de utilizar la teoría del modelo de urna, desarrollaremos un modelo basado en datos.</p>
</div>
</div>
<div id="data-driven-model" class="section level2">
<h2><span class="header-section-number">2.2</span> Modelos basados en datos</h2>
<p>Para cada encuestador, recopilemos su último resultado informado antes de las elecciones:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">one_poll_per_pollster &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span>
<span class="kw">filter</span>(enddate <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(enddate)) <span class="op">%&gt;%</span>
<span class="kw">ungroup</span>()</code></pre></div>
<p>Aquí hay un histograma de los datos para estos 15 encuestadores:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qplot</span>(spread, <span class="dt">data =</span> one_poll_per_pollster, <span class="dt">binwidth =</span> <span class="fl">0.01</span>)</code></pre></div>
<p><img src="libro_files/figure-html/pollster-bias-histogram-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>En la sección anterior, vimos que usar la teoría del modelo de urna para combinar estos resultados podría no ser apropiado debido al efecto de encuestador. En cambio, modelaremos estos datos de propagación directamente.</p>
<p>El nuevo modelo también puede considerarse como un modelo de urna, aunque la conexión no es tan directa. En lugar de 0s (republicanos) y 1s (demócratas), nuestra urna ahora contiene resultados de encuestas de todos los posibles encuestadores. Suponemos que el valor esperado de nuestra urna es la extensión real <span class="math inline">\(d=2p-1\)</span>.</p>
<p>Como en lugar de 0s y 1s, nuestra urna contiene números continuos entre -1 y 1, la desviación estándar de la urna ya no es $ $. Rather than voter sampling variability, the standard error now includes the pollster-to-pollster variability. Our new urn also includes the sampling variability from the polling. Regardless, this standard deviation is now an unknown parameter. In statistics textbooks, the Greek symbol $$ se usa para representar este parámetro.</p>
<p>En resumen, tenemos dos parámetros desconocidos: el valor esperado <span class="math inline">\(d\)</span> y la desviación estándar <span class="math inline">\(\sigma\)</span>.</p>
<p>Nuestra tarea es estimar <span class="math inline">\(d\)</span>. Porque modelamos los valores observados <span class="math inline">\(X_1,\dots X_N\)</span> como muestra aleatoria de la urna, el CLT aún podría funcionar en esta situación porque es un promedio de variables aleatorias independientes. Para un tamaño de muestra suficientemente grande <span class="math inline">\(N\)</span>, la distribución de probabilidad de la muestra promedio ${X} $ is approximately normal with expected value $$ and standard error $/ $. If we are willing to consider $ N = 15 $ lo suficientemente grande, podemos usar esto para construir intervalos de confianza.</p>
<p>Un problema es que no sabemos <span class="math inline">\(\sigma\)</span>. Pero la teoría nos dice que podemos estimar el modelo de urna <span class="math inline">\(\sigma\)</span> con la _ desviación estándar de muestra_ definida como $ s = $.</p>
<p>A diferencia de la definición de desviación estándar de la población, ahora dividimos por <span class="math inline">\(N-1\)</span>. Esto hace <span class="math inline">\(s\)</span> una mejor estimación de <span class="math inline">\(\sigma\)</span>. Hay una explicación matemática para esto, que se explica en la mayoría de los libros de texto de estadística, pero no la cubrimos aquí.</p>
<p>Los <code>sd</code> la función en R calcula la desviación estándar de la muestra:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(one_poll_per_pollster<span class="op">$</span>spread)
<span class="co">#&gt; [1] 0.0242</span></code></pre></div>
<p>Ahora estamos listos para formar un nuevo intervalo de confianza basado en nuestro nuevo modelo basado en datos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span>one_poll_per_pollster <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread),
<span class="dt">se =</span> <span class="kw">sd</span>(spread)<span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">length</span>(spread))) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">start =</span> avg <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>se,
<span class="dt">end =</span> avg <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>se)
<span class="kw">round</span>(results <span class="op">*</span><span class="st"> </span><span class="dv">100</span>, <span class="dv">1</span>)
<span class="co">#&gt;   avg  se start end</span>
<span class="co">#&gt; 1 2.9 0.6   1.7 4.1</span></code></pre></div>
<p>Nuestro intervalo de confianza es más amplio ahora ya que incorpora la variabilidad del encuestador. Incluye el resultado de la noche electoral del 2.1%. Además, tenga en cuenta que era lo suficientemente pequeño como para no incluir 0, lo que significa que estábamos seguros de que Clinton ganaría el voto popular.</p>
<p>¿Estamos listos ahora para declarar una probabilidad de que Clinton gane el voto popular? Aún no. En nuestro modelo <span class="math inline">\(d\)</span> es un parámetro fijo, por lo que no podemos hablar de probabilidades. Para proporcionar probabilidades, necesitaremos aprender sobre las estadísticas bayesianas.</p>
</div>
<div id="ejercicios-4" class="section level2">
<h2><span class="header-section-number">2.3</span> Ejercicios</h2>
<p>Hemos estado utilizando modelos de urna para motivar el uso de modelos de probabilidad. La mayoría de las aplicaciones de ciencia de datos no están relacionadas con los datos obtenidos de urnas. Más comunes son los datos que provienen de individuos. La razón por la que la probabilidad juega un papel aquí es porque los datos provienen de una muestra aleatoria. La muestra aleatoria se toma de una población y la urna sirve como analogía para la población.</p>
<p>Volvamos al conjunto de datos de alturas. Supongamos que consideramos a los machos en nuestro curso como la población.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dslabs)
<span class="kw">data</span>(heights)
x &lt;-<span class="st"> </span>heights <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(sex <span class="op">==</span><span class="st"> &quot;Male&quot;</span>) <span class="op">%&gt;%</span>
<span class="kw">pull</span>(height)</code></pre></div>
<p>1. Matemáticamente hablando, <code>x</code> es nuestra población Usando la analogía de la urna, tenemos una urna con los valores de <code>x</code> en eso. ¿Cuáles son las desviaciones promedio y estándar de nuestra población?</p>
<p>2. Llame al promedio de población calculado arriba <span class="math inline">\(\mu\)</span> y la desviación estándar <span class="math inline">\(\sigma\)</span>. Ahora tome una muestra de tamaño 50, con reemplazo, y construya una estimación para <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>.</p>
<p>3. ¿Qué nos dice la teoría sobre el promedio de muestra ${X} $ and how it is related to $$?</p>
<ol style="list-style-type: lower-alpha">
<li>Es prácticamente idéntico a <span class="math inline">\(\mu\)</span>. si. Es una variable aleatoria con valor esperado. <span class="math inline">\(\mu\)</span> y error estándar <span class="math inline">\(\sigma/\sqrt {N}\)</span>.</li>
<li>Es una variable aleatoria con valor esperado. <span class="math inline">\(\mu\)</span> y error estándar <span class="math inline">\(\sigma\)</span>. re. No contiene información</li>
</ol>
<p>4. Entonces, ¿cómo es esto útil? Vamos a utilizar un ejemplo demasiado simplificado pero ilustrativo. Supongamos que queremos saber la altura promedio de nuestros estudiantes varones, pero solo llegamos a medir 50 de los 708. Usaremos ${X} $ as our estimate. We know from the answer to exercise 3 that the standard estimate of our error ${X}-$ is $/ $. We want to compute this, but we don’t know $$. Based on what is described in this section, show your estimate of $$.</p>
<p>5. Ahora que tenemos una estimación de <span class="math inline">\(\sigma\)</span>, llamemos a nuestra estimación <span class="math inline">\(s\)</span>. Construya un intervalo de confianza del 95% para <span class="math inline">\(\mu\)</span>.</p>
<p>6. Ahora ejecute una simulación de Monte Carlo en la que calcule 10,000 intervalos de confianza como acaba de hacer. ¿Qué proporción de estos intervalos incluyen <span class="math inline">\(\mu\)</span>?</p>
<p>7. En esta sección, hablamos sobre el sesgo de encuestador. Utilizamos la visualización para motivar la presencia de tal sesgo. Aquí le daremos un tratamiento más riguroso. Consideraremos dos encuestadores que realizaron encuestas diarias. Examinaremos las encuestas nacionales del mes anterior a las elecciones.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(polls_us_election_<span class="dv">2016</span>)
polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(pollster <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Rasmussen Reports/Pulse Opinion Research&quot;</span>,
<span class="st">&quot;The Times-Picayune/Lucid&quot;</span>) <span class="op">&amp;</span>
enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-15&quot;</span> <span class="op">&amp;</span>
state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span>) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</code></pre></div>
<p>Queremos responder la pregunta: ¿hay un sesgo en la encuesta? Haz un diagrama que muestre los diferenciales para cada encuesta.</p>
<p>8. Los datos parecen sugerir que hay una diferencia. Sin embargo, estos los datos están sujetos a variabilidad. Quizás las diferencias que observamos se deben al azar.</p>
<p>La teoría del modelo de urna no dice nada sobre el efecto encuestador. Bajo el modelo de urna, ambos encuestadores tienen el mismo valor esperado: la diferencia del día de las elecciones, que llamamos <span class="math inline">\(d\)</span>.</p>
<p>Para responder a la pregunta “¿hay un modelo de urna?”, Modelaremos los datos observados $ Y_ {i,j}$ de la siguiente manera:</p>
<p><span class="math display">\[
Y_{i,j} = d + b_i +\varepsilon_{i,j}
\]</span></p>
<p>con <span class="math inline">\(i=1,2\)</span> indexando los dos encuestadores, <span class="math inline">\(b_i\)</span> el sesgo para el encuestador <span class="math inline">\(i\)</span> y <span class="math inline">\(\varepsilon_ij\)</span> encuesta a encuesta variabilidad casual. Asumimos el <span class="math inline">\(\varepsilon\)</span> son independientes entre sí, tienen valor esperado <span class="math inline">\(0\)</span> y desviación estándar <span class="math inline">\(\sigma_i\)</span> a pesar de <span class="math inline">\(j\)</span>.</p>
<p>¿Cuál de las siguientes representa mejor nuestra pregunta?</p>
<ol style="list-style-type: lower-alpha">
<li>Es <span class="math inline">\(\varepsilon_ {i,j}\)</span> = 0? si. ¿Qué tan cerca están los $ Y_ {i,j} $ to $ d $?</li>
<li>Es <span class="math inline">\(b_1\neq b_2\)</span>? re. Son <span class="math inline">\(b_1 = 0\)</span> y <span class="math inline">\(b_2 = 0\)</span> ?</li>
</ol>
<p>9. En el lado derecho de este modelo solo $_ {i,j} $ is a random variable. The other two are constants. What is the expected value of $ Y_ {1,j}$?</p>
<p>10. Supongamos que definimos <span class="math inline">\(\bar {Y}_1\)</span> as the average of poll results from the first poll, $ Y_ {1,1},, Y_ {1,N_1} $ with $ N_1 $ el número de encuestas realizadas por el primer encuestador:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls <span class="op">%&gt;%</span>
<span class="kw">filter</span>(pollster<span class="op">==</span><span class="st">&quot;Rasmussen Reports/Pulse Opinion Research&quot;</span>) <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">N_1 =</span> <span class="kw">n</span>())</code></pre></div>
<p>¿Cuáles son los valores esperados <span class="math inline">\(\bar {Y}_1\)</span>?</p>
<p>11. ¿Cuál es el error estándar de <span class="math inline">\(\bar? {Y}_1\)</span> ?</p>
<p>12. Supongamos que definimos <span class="math inline">\(\bar {Y}_2\)</span> as the average of poll results from the first poll, $ Y_ {2,1},, Y_ {2,N_2} $ with $ N_2 $ the number of polls conducted by the first pollster. What is the expected value <span class="math inline">\(\bar {Y}_2\)</span>?</p>
<p>13. ¿Cuál es el error estándar de <span class="math inline">\(\bar? {Y}_2\)</span> ?</p>
<p>14. Usando lo que aprendimos respondiendo las preguntas anteriores, ¿cuál es el valor esperado de <span class="math inline">\(\bar? {Y}_{2} -\bar {Y}_1\)</span>?</p>
<p>15. Usando lo que aprendimos al responder las preguntas anteriores, ¿cuál es el error estándar de <span class="math inline">\(\bar? {Y}_{2} -\bar {Y}_1\)</span>?</p>
<p>Dieciséis. La respuesta a la pregunta anterior depende de <span class="math inline">\(\sigma_1\)</span> y <span class="math inline">\(\sigma_2\)</span>, que no sabemos. Aprendimos que podemos estimarlos con la desviación estándar de la muestra. Escribe un código que calcule estas dos estimaciones.</p>
<p>17. ¿Qué nos dice el CLT sobre la distribución de <span class="math inline">\(\bar {Y}_2 -\bar {Y}_1\)</span>?</p>
<ol style="list-style-type: lower-alpha">
<li>Nada porque este no es el promedio de una muestra. si. Porque el $ Y_ {ij}$ son aproximadamente normales, también lo son los promedios.</li>
<li>Tenga en cuenta que <span class="math inline">\(\bar {Y}_2\)</span> and <span class="math inline">\(\bar {Y}_1\)</span> are sample averages, so if we assume $ N_2 $ and $ N_1 $ son lo suficientemente grandes, cada uno es aproximadamente normal. La diferencia de las normales también es normal. re. Los datos no son 0 o 1, por lo que CLT no se aplica.</li>
</ol>
<p>18. Hemos construido una variable aleatoria que tiene un valor esperado. <span class="math inline">\(b_2 - b_1\)</span>, la diferencia de sesgo del encuestador. Si nuestro modelo se cumple, entonces esta variable aleatoria tiene una distribución aproximadamente normal y conocemos su error estándar. El error estándar depende de <span class="math inline">\(\sigma_1\)</span> y <span class="math inline">\(\sigma_2\)</span>, pero podemos tapar las desviaciones estándar de muestra que calculamos anteriormente. Comenzamos preguntando: es <span class="math inline">\(b_2 - b_1\)</span> diferente de 0? Use toda la información que hemos aprendido anteriormente para construir un intervalo de confianza del 95% para la diferencia <span class="math inline">\(b_2\)</span> y <span class="math inline">\(b_1\)</span>.</p>
<p>19. El intervalo de confianza nos dice que hay un efecto encuestador relativamente fuerte que resulta en una diferencia de aproximadamente 5%. La variabilidad aleatoria no parece explicarlo. Podemos calcular un valor p para transmitir el hecho de que el azar no lo explica. ¿Cuál es el valor p?</p>
<p>20. La estadística formada dividiendo nuestra estimación de <span class="math inline">\(b_2-b_1\)</span> por su error estándar estimado:</p>
<p><span class="math display">\[
\frac{\bar{Y}_2 -\bar{Y}_1}{\sqrt{s_2^2/N_2 + s_1^2/N_1}}
\]</span></p>
<p>se llama la estadística t. Ahora observe que tenemos más de dos encuestadores. También podemos probar el efecto de encuestador utilizando todos los encuestadores, no solo dos. La idea es comparar la variabilidad entre encuestas con la variabilidad dentro de las encuestas. De hecho, podemos construir estadísticas para probar los efectos y aproximar su distribución. El área de estadísticas que hace esto se llama Análisis de varianza o ANOVA. No lo cubrimos aquí, pero ANOVA proporciona un conjunto muy útil de herramientas para responder preguntas como: ¿hay un efecto encuestador?</p>
<p>Para este ejercicio, cree una nueva tabla:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-15&quot;</span> <span class="op">&amp;</span>
state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span>) <span class="op">%&gt;%</span>
<span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span>
<span class="kw">filter</span>(<span class="kw">n</span>() <span class="op">&gt;=</span><span class="st"> </span><span class="dv">5</span>) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="kw">ungroup</span>()</code></pre></div>
<p>Calcule el promedio y la desviación estándar para cada encuestador y examine la variabilidad entre los promedios y cómo se compara con la variabilidad dentro de los encuestadores, resumida por la desviación estándar.</p>

</div>
<div id="bayesian-statistics" class="section level2">
<h2><span class="header-section-number">2.4</span> Estadísticas bayesianas</h2>
<p>¿Qué significa que un pronosticador electoral nos diga que un candidato determinado tiene un 90% de posibilidades de ganar? En el contexto del modelo de urna, esto sería equivalente a afirmar que la probabilidad <span class="math inline">\(p&gt;0.5\)</span> es 90% Sin embargo, como discutimos anteriormente, en el modelo de urna <span class="math inline">\(p\)</span> es un parámetro fijo y no tiene sentido hablar de probabilidad. Con estadísticas bayesianas, modelamos <span class="math inline">\(p\)</span> como variable aleatoria y, por lo tanto, una declaración como “90% de probabilidad de ganar” es coherente con el enfoque.</p>
<p>Los pronosticadores también usan modelos para describir la variabilidad en diferentes niveles. Por ejemplo, la variabilidad del muestreo, la variabilidad de encuestador a encuestador, la variabilidad del día a día y la variabilidad de elección a elección. Uno de los enfoques más exitosos utilizados para esto son los modelos jerárquicos, que pueden explicarse en el contexto de las estadísticas bayesianas.</p>
<p>En este capítulo describimos brevemente las estadísticas bayesianas. Para un tratamiento en profundidad de este tema, recomendamos uno de los siguientes libros de texto:</p>
<ul>
<li><p>Berger JO (1985). Teoría de decisión estadística y análisis bayesiano, 2a edición. Springer-Verlag.</p></li>
<li><p>Lee PM (1989). Estadísticas bayesianas: una introducción. Oxford</p></li>
</ul>
<div id="teorema-de-bayes" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Teorema de Bayes</h3>
<p>Comenzamos describiendo el teorema de Bayes. Hacemos esto usando una hipotética prueba de fibrosis quística como ejemplo. Supongamos que una prueba de fibrosis quística tiene una precisión del 99%. Vamos a utilizar la siguiente notación:</p>
<p><span class="math display">\[
\mbox{Prob}(+\mid D=1)=0.99,\mbox{Prob}(-\mid D=0)=0.99
\]</span></p>
<p>con <span class="math inline">\(+\)</span> lo que significa una prueba positiva y <span class="math inline">\(D\)</span> representando si realmente tiene la enfermedad (1) o no (0).</p>
<p>Supongamos que seleccionamos una persona al azar y dan positivo. ¿Cuál es la probabilidad de que tengan la enfermedad? Escribimos esto como $(D = 1+)? $ The cystic fibrosis rate is 1 in 3,900 which implies that $(D = 1) = 0.00025 $. Para responder a esta pregunta, utilizaremos el teorema de Bayes, que en general nos dice que:</p>
<p><span class="math display">\[
\mbox{Pr}(A\mid B) =\frac{\mbox{Pr}(B\mid A)\mbox{Pr}(A)}{\mbox{Pr}(B)}
\]</span></p>
<p>Esta ecuación aplicada a nuestro problema se convierte en:</p>
<p><span class="math display">\[
\begin{aligned}
\mbox{Pr}(D=1\mid +) &amp; =\frac{ P(+\mid D=1)\cdot P(D=1)} {\mbox{Pr}(+)}\\
&amp; =\frac{\mbox{Pr}(+\mid D=1)\cdot P(D=1)} {\mbox{Pr}(+\mid D=1)\cdot P(D=1) +\mbox{Pr}(+\mid D=0)\mbox{Pr}( D=0)}
\end{aligned}
\]</span></p>
<p>Conectando los números que obtenemos:</p>
<p><span class="math display">\[
\frac{0.99\cdot 0.00025}{0.99\cdot 0.00025 + 0.01\cdot (.99975)} = 0.02
\]</span></p>
<p>Esto dice que a pesar de que la prueba tiene una precisión de 0.99, la probabilidad de que la enfermedad reciba una prueba positiva es de solo 0.02. Esto puede parecer contrario a la intuición para algunos, pero la razón de esto es porque tenemos que tener en cuenta la muy rara probabilidad de que una persona, elegida al azar, tenga la enfermedad. Para ilustrar esto, ejecutamos una simulación de Monte Carlo.</p>
</div>
</div>
<div id="simulacion-del-teorema-de-bayes" class="section level2">
<h2><span class="header-section-number">2.5</span> Simulación del teorema de Bayes</h2>
<p>La siguiente simulación está destinada a ayudarlo a visualizar el teorema de Bayes. Comenzamos seleccionando aleatoriamente a 100,000 personas de una población en la cual la enfermedad en cuestión tiene una prevalencia de 1 en 4,000.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prev &lt;-<span class="st"> </span><span class="fl">0.00025</span>
N &lt;-<span class="st"> </span><span class="dv">100000</span>
outcome &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;Disease&quot;</span>,<span class="st">&quot;Healthy&quot;</span>), N, <span class="dt">replace =</span> <span class="ot">TRUE</span>,
<span class="dt">prob =</span> <span class="kw">c</span>(prev, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>prev))</code></pre></div>
<p>Tenga en cuenta que hay muy pocas personas con la enfermedad:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">N_D &lt;-<span class="st"> </span><span class="kw">sum</span>(outcome <span class="op">==</span><span class="st"> &quot;Disease&quot;</span>)
N_D
<span class="co">#&gt; [1] 23</span>
N_H &lt;-<span class="st"> </span><span class="kw">sum</span>(outcome <span class="op">==</span><span class="st"> &quot;Healthy&quot;</span>)
N_H
<span class="co">#&gt; [1] 99977</span></code></pre></div>
<p>Además, hay muchos sin la enfermedad, lo que hace más probable que veamos algunos falsos positivos dado que la prueba no es perfecta. Ahora cada persona se hace la prueba, que es correcta el 99% del tiempo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">accuracy &lt;-<span class="st"> </span><span class="fl">0.99</span>
test &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;character&quot;</span>, N)
test[outcome <span class="op">==</span><span class="st"> &quot;Disease&quot;</span>] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;+&quot;</span>, <span class="st">&quot;-&quot;</span>), N_D, <span class="dt">replace =</span> <span class="ot">TRUE</span>,
<span class="dt">prob =</span> <span class="kw">c</span>(accuracy, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>accuracy))
test[outcome <span class="op">==</span><span class="st"> &quot;Healthy&quot;</span>] &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;-&quot;</span>, <span class="st">&quot;+&quot;</span>), N_H, <span class="dt">replace =</span> <span class="ot">TRUE</span>,
<span class="dt">prob =</span> <span class="kw">c</span>(accuracy, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>accuracy))</code></pre></div>
<p>Debido a que hay muchos más controles que casos, incluso con una tasa baja de falsos positivos obtenemos más controles que los casos en el grupo que dieron positivo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(outcome, test)
<span class="co">#&gt;          test</span>
<span class="co">#&gt; outcome       -     +</span>
<span class="co">#&gt;   Disease     0    23</span>
<span class="co">#&gt;   Healthy 99012   965</span></code></pre></div>
<p>De esta tabla, vemos que la proporción de pruebas positivas que tienen la enfermedad es 23 fuera de 988. Podemos ejecutar esto una y otra vez para ver que, de hecho, la probabilidad converge a aproximadamente 0.022.</p>
<div id="bayes-en-la-practica" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Bayes en la práctica</h3>
<p>José Iglesias es un jugador de béisbol profesional. En abril de 2013, cuando comenzaba su carrera, se desempeñaba bastante bien:</p>
<table>
<thead>
<tr class="header">
<th>El</th>
<th>Mes</th>
<th>En los murciélagos</th>
<th>H</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>El</td>
<td>Abril</td>
<td>20</td>
<td>9</td>
</tr>
</tbody>
</table>
<p>El promedio de bateo ( <code>AVG</code>) la estadística es una forma de medir el éxito. En términos generales, nos dice la tasa de éxito al batear. Un <code>AVG</code> de .450 significa que José ha tenido éxito el 45% de las veces que ha bateado ( <code>At Bats</code>) que es bastante alto, históricamente hablando. Tenga en cuenta que nadie ha terminado una temporada con un <code>AVG</code> de .400 o más desde que Ted Williams lo hizo en 1941! Para ilustrar la forma en que los modelos jerárquicos son poderosos, intentaremos predecir el promedio de bateo de José al final de la temporada. Tenga en cuenta que en una temporada típica, los jugadores tienen alrededor de 500 al bate.</p>
<p>Con las técnicas que hemos aprendido hasta ahora, denominadas técnicas frecuentes, lo mejor que podemos hacer es proporcionar un intervalo de confianza. Podemos pensar en los resultados de golpear como un binomio con una tasa de éxito de <span class="math inline">\(p\)</span>. Entonces, si la tasa de éxito es de .450, el error estándar de solo 20 en los bates es:</p>
<p><span class="math display">\[
\sqrt{\frac{.450 (1-.450)}{20}}=.111
\]</span></p>
<p>Esto significa que nuestro intervalo de confianza es <span class="math inline">\(.450 - .222\)</span> a <span class="math inline">\(.450 + .222\)</span> o <span class="math inline">\(.228\)</span> a <span class="math inline">\(.672\)</span>.</p>
<p>Esta predicción tiene dos problemas. Primero, es muy grande, por lo que no es muy útil. Segundo, está centrado en .450, lo que implica que nuestra mejor suposición es que este nuevo jugador romperá el récord de Ted Williams.</p>
<p>Si sigue el béisbol, esta última afirmación parecerá incorrecta y esto se debe a que está utilizando implícitamente un modelo jerárquico que tiene en cuenta la información de años de seguir el béisbol. Aquí mostramos cómo podemos cuantificar esta intuición.</p>
<p>Primero, exploremos la distribución de los promedios de bateo para todos los jugadores con más de 500 al bate durante las tres temporadas anteriores:</p>
<p><img src="libro_files/figure-html/batting-averages-histogram-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>El jugador promedio tenía un <code>AVG</code> de .275 y la desviación estándar de la población de jugadores fue de 0.027. Entonces podemos ver que .450 sería una anomalía, ya que está a más de seis desviaciones estándar de la media.</p>
<p>Entonces, ¿tiene suerte José o es el mejor bateador visto en los últimos 50 años? Quizás sea una combinación de suerte y talento. ¿Pero cuánto de cada uno? Si nos convencemos de que tiene suerte, deberíamos cambiarlo por un equipo que confíe en la observación de .450 y tal vez esté sobreestimando su potencial.</p>
</div>
</div>
<div id="modelos-jerarquicos" class="section level2">
<h2><span class="header-section-number">2.6</span> Modelos jerárquicos</h2>
<p>El modelo jerárquico proporciona una descripción matemática de cómo llegamos a ver la observación de .450. Primero, elegimos un jugador al azar con una habilidad intrínseca resumida por, por ejemplo, <span class="math inline">\(p\)</span>. Luego vemos 20 resultados aleatorios con probabilidad de éxito <span class="math inline">\(p\)</span>.</p>
<p>Utilizamos un modelo para representar dos niveles de variabilidad en nuestros datos. Primero, a cada jugador se le asigna una habilidad natural para golpear. Usaremos el símbolo <span class="math inline">\(p\)</span> para representar esta habilidad. Tu puedes pensar en <span class="math inline">\(p\)</span> como el promedio de bateo al que convergerías si este jugador en particular bateara una y otra vez.</p>
<p>En base a las parcelas que mostramos anteriormente, asumimos que <span class="math inline">\(p\)</span> tiene una distribución normal. Con valor esperado .270 y error estándar 0.027.</p>
<p>Ahora el segundo nivel de variabilidad tiene que ver con la suerte al batear. Independientemente de lo bueno que sea el jugador, a veces tienes mala suerte y a veces tienes buena suerte. En cada turno al bate, este jugador tiene una probabilidad de éxito <span class="math inline">\(p\)</span>. Si sumamos estos éxitos y fracasos, entonces el CLT nos dice que el promedio observado, llámelo <span class="math inline">\(Y\)</span>, tiene una distribución normal con el valor esperado <span class="math inline">\(p\)</span> y error estándar $ $ with $ N $ el número de al bate.</p>
<p>Los libros de texto estadísticos escribirán el modelo así: <span class="math display">\[
\begin{aligned}
p &amp;\sim N(\mu,\tau^2)\\
Y\mid p &amp;\sim N(p,\sigma^2)
\end{aligned}
\]</span> Aquí el <span class="math inline">\(\sim\)</span> el símbolo nos dice que la variable aleatoria a la izquierda del símbolo sigue la distribución a la derecha y <span class="math inline">\(N(a,b^2)\)</span> representa la distribución normal con media <span class="math inline">\(a\)</span> y desviación estándar <span class="math inline">\(b\)</span>. Los <span class="math inline">\(\mid\)</span> se lee como <em>condicionado en</em>, y significa que estamos tratando la variable aleatoria a la derecha del símbolo como se conoce. Nos referimos al modelo como jerárquico porque necesitamos saber <span class="math inline">\(p\)</span>, el primer nivel, para modelar <span class="math inline">\(Y\)</span>, el segundo nivel. En nuestro ejemplo, el primer nivel describe la aleatoriedad en la asignación de talento a un jugador y el segundo describe la aleatoriedad en el rendimiento de este jugador en particular una vez que hemos fijado el parámetro de talento. En un marco bayesiano, el primer nivel se llama _ distribución anterior_ y el segundo la _ distribución de muestreo_. El análisis de datos que hemos realizado aquí sugiere que establezcamos <span class="math inline">\(\mu = .270\)</span>, <span class="math inline">\(\tau = 0.027\)</span>y <span class="math inline">\(\sigma^2 = p(1-p)/N\)</span>.</p>
<p>Ahora, usemos este modelo para los datos de José. Supongamos que queremos predecir su habilidad innata en la forma de su verdadero promedio de bateo <span class="math inline">\(p\)</span>. Este sería el modelo jerárquico para nuestros datos:</p>
<p><span class="math display">\[
\begin{aligned}
p &amp;\sim N(.275, .027^2)\\
Y\mid p &amp;\sim N(p, .111^2)
\end{aligned}
\]</span></p>
<p>Ahora estamos listos para calcular una distribución posterior para resumir nuestra predicción de <span class="math inline">\(p\)</span>. La versión continua de la regla de Bayes se puede usar aquí para derivar la _ función de probabilidad posterior_, que es la distribución de <span class="math inline">\(p\)</span> suponiendo que observemos <span class="math inline">\(Y=y\)</span>. En nuestro caso, podemos demostrar que cuando arreglamos <span class="math inline">\(Y=y\)</span>, <span class="math inline">\(p\)</span> sigue una distribución normal con el valor esperado:</p>
<p><span class="math display">\[
\begin{aligned}
\mbox{E}(p\mid Y=y) &amp;= B\mu + (1-B) y\\
&amp;=\mu + (1-B)(y-\mu)\\
\mbox{with } B &amp;=\frac{\sigma^2}{\sigma^2+\tau^2}
\end{aligned}
\]</span></p>
<p>Este es un promedio ponderado del promedio de la población. <span class="math inline">\(\mu\)</span> y los datos observados <span class="math inline">\(y\)</span>. El peso depende de la DE de la población. <span class="math inline">\(\tau\)</span> y la SD de nuestros datos observados <span class="math inline">\(\sigma\)</span>. Este promedio ponderado a veces se denomina <em>shrinking</em> porque <em>shrinks</em> estima hacia una media previa. En el caso de José Iglesias, tenemos:</p>
<p><span class="math display">\[
\begin{aligned}
\mbox{E}(p\mid Y=.450) &amp;= B\times .275 + (1 - B)\times .450\\
&amp;= .275 + (1 - B)(.450 - .275)\\
B &amp;=\frac{.111^2}{.111^2 + .027^2} = 0.944\\
\mbox{E}(p\mid Y=450) &amp;\approx .285
\end{aligned}
\]</span></p>
<p>No mostramos la derivación aquí, pero el error estándar puede ser:</p>
<p><span class="math display">\[
\mbox{SE}(p\mid y)^2 =\frac{1}{1/\sigma^2+1/\tau^2}
=\frac{1}{1/.111^2 + 1/.027^2} = 0.00069
\]</span> y la desviación estándar es por lo tanto <span class="math inline">\(0.026\)</span>. Entonces comenzamos con un intervalo de confianza frecuente del 95% que ignoraba los datos de otros jugadores y resumía solo los datos de José: .450 <span class="math inline">\(\pm\)</span> 0.220. Luego, utilizamos un enfoque bayesiano que incorporaba datos de otros jugadores y otros años para obtener una probabilidad posterior. En realidad, esto se conoce como un enfoque empírico de Bayes porque utilizamos datos para construir el anterior. Desde la parte posterior, podemos informar lo que se llama un intervalo creíble del 95% informando una región, centrada en la media, con una probabilidad del 95% de ocurrir. En nuestro caso, esto resulta ser: .285 <span class="math inline">\(\pm\)</span> 0.052.</p>
<p>El intervalo creíble bayesiano sugiere que si otro equipo está impresionado por la observación de .450, deberíamos considerar cambiar a José, ya que pronosticamos que estará ligeramente por encima del promedio. Curiosamente, los Medias Rojas cambiaron a José a los Tigres de Detroit en julio. Estos son los promedios de bateo de José Iglesias para los próximos cinco meses:</p>
<table>
<thead>
<tr class="header">
<th>Mes</th>
<th>Al bate</th>
<th>Hits</th>
<th>AVG</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Abril</td>
<td>20</td>
<td>9</td>
<td>.450</td>
</tr>
<tr class="even">
<td>Mayo</td>
<td>26</td>
<td>11</td>
<td>.423</td>
</tr>
<tr class="odd">
<td>Junio</td>
<td>86</td>
<td>34</td>
<td>.395</td>
</tr>
<tr class="even">
<td>Julio</td>
<td>83</td>
<td>17</td>
<td>.205</td>
</tr>
<tr class="odd">
<td>Agosto</td>
<td>85</td>
<td>25</td>
<td>.294</td>
</tr>
<tr class="even">
<td>Septiembre</td>
<td>50</td>
<td>10</td>
<td>.200</td>
</tr>
<tr class="odd">
<td>Total sin abril</td>
<td>330</td>
<td>97</td>
<td>.293</td>
</tr>
</tbody>
</table>
<p>Aunque ambos intervalos incluyeron el promedio final de bateo, el intervalo creíble bayesiano proporcionó una predicción mucho más precisa. En particular, predijo que no sería tan bueno durante el resto de la temporada.</p>
</div>
<div id="ejercicios-5" class="section level2">
<h2><span class="header-section-number">2.7</span> Ejercicios</h2>
<p>1. En 1999, en Inglaterra, Sally Clark ^ [<a href="https://en.wikipedia.org/wiki/Sally_Clark" class="uri">https://en.wikipedia.org/wiki/Sally_Clark</a>] fue declarada culpable del asesinato de dos de sus hijos. Ambos bebés fueron encontrados muertos por la mañana, uno en 1996 y otro en 1998. En ambos casos, afirmó que la causa de la muerte fue el síndrome de muerte súbita del lactante (SMSL). No se encontró evidencia de daño físico en los dos bebés, por lo que la principal evidencia en su contra fue el testimonio del profesor Sir Roy Meadow, quien testificó que las posibilidades de que dos bebés murieran de SMSL eran de 1 en 73 millones. Llegó a esta cifra al encontrar que la tasa de SMSL era de 1 en 8,500 y luego calcular que la posibilidad de dos casos de SMSL era de 8,500 <span class="math inline">\(\times\)</span> 8,500 <span class="math inline">\(\approx\)</span> 73 millones. ¿Con cuál de los siguientes está de acuerdo?</p>
<ol style="list-style-type: lower-alpha">
<li>Sir Meadow supuso que la probabilidad de que el segundo hijo fuera afectado por el SMSL era independiente de la del primer hijo afectado, ignorando así las posibles causas genéticas. Si la genética juega un papel, entonces: <span class="math inline">\(\mbox {Pr}(\mbox {second case of SIDS}\mid\mbox {first case of SIDS}) &lt;\mbox {P} r (\mbox {first case of SIDS})\)</span>. si. Nada. La regla de multiplicación siempre se aplica de esta manera: $(A B) =(A)(B) $</li>
<li>Sir Meadow es un experto y debemos confiar en sus cálculos. re. Los números no mienten.</li>
</ol>
<p>2. Supongamos que de hecho hay un componente genético en SIDS y la probabilidad de $() = 1/100 $, es mucho más alto que 1 en 8,500. ¿Cuál es la probabilidad de que sus dos hijos mueran de SMSL?</p>
<p>3. Muchos informes de prensa declararon que el experto afirmó que la probabilidad de que Sally Clark sea inocente es de 1 en 73 millones. Quizás el jurado y el juez también interpretaron el testimonio de esta manera. Esta probabilidad se puede escribir como la probabilidad de que una madre sea un psicópata asesino de hijos, dado que dos de sus hijos son encontrados muertos sin evidencia de daño físico. Según la regla de Bayes, ¿qué es esto?</p>
<p>4. Suponga que la posibilidad de que un psicópata asesino de hijos encuentre la manera de matar a sus hijos, sin dejar evidencia de daño físico, es:</p>
<p><span class="math display">\[
\mbox{Pr}(A\mid B) = 0.50
\]</span></p>
<p>con A = dos de sus hijos son encontrados muertos sin evidencia de daño físico y B = una madre es una psicópata asesina de hijos = 0.50. Suponga que la tasa de madres psicópatas que asesinan hijos es de 1 en 1,000,000. Según el teorema de Bayes, ¿cuál es la probabilidad de $? {Pr}(BA) $?</p>
<p>5/. Después de que Sally Clark fue declarada culpable, la Royal Statistical Society emitió un comunicado diciendo que “no había base estadística” para el reclamo del experto. Expresaron preocupación por el “mal uso de las estadísticas en los tribunales”. Finalmente, Sally Clark fue absuelta en junio de 2003. ¿Qué extrañó el experto?</p>
<ol style="list-style-type: lower-alpha">
<li>Cometió un error aritmético. si. Cometió dos errores. Primero, hizo un mal uso de la regla de multiplicación y no tuvo en cuenta lo raro que es para una madre asesinar a sus hijos. Después de usar la regla de Bayes, encontramos una probabilidad más cercana a 0.5 que 1 en 73 millones.</li>
<li>Mezcló el numerador y el denominador de la regla de Bayes. re. No usó R.</li>
</ol>
<p>6. Florida es uno de los estados más vigilados en las elecciones de EE. UU. Porque tiene muchos votos electorales, y las elecciones son generalmente cerradas, y Florida tiende a ser un estado decisivo que puede votar de cualquier manera. Cree la siguiente tabla con las encuestas realizadas durante las últimas dos semanas:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(dslabs)
<span class="kw">data</span>(polls_us_election_<span class="dv">2016</span>)
polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;Florida&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-11-04&quot;</span> ) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</code></pre></div>
<p>Tome la extensión promedio de estas encuestas. El CLT nos dice que este promedio es aproximadamente normal. Calcule un promedio y proporcione una estimación del error estándar. Guarde sus resultados en un objeto llamado <code>results</code>.</p>
<p>7. Ahora suponga un modelo bayesiano que establece la distribución previa para la propagación de la noche electoral de Florida <span class="math inline">\(d\)</span> ser normal con el valor esperado <span class="math inline">\(\mu\)</span> y desviación estándar <span class="math inline">\(\tau\)</span>. ¿Cuáles son las interpretaciones de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\tau\)</span>?</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\mu\)</span> y <span class="math inline">\(\tau\)</span> son números arbitrarios que nos permiten hacer declaraciones de probabilidad sobre <span class="math inline">\(d\)</span>. si. <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\tau\)</span> resuma lo que predeciríamos para Florida antes de ver las encuestas. Basado en elecciones pasadas, estableceríamos <span class="math inline">\(\mu\)</span> cerca de 0 porque tanto republicanos como demócratas han ganado, y <span class="math inline">\(\tau\)</span> a aproximadamente <span class="math inline">\(0.02\)</span>, porque estas elecciones tienden a ser cercanas.</li>
<li><span class="math inline">\(\mu\)</span> y <span class="math inline">\(\tau\)</span> resumir lo que queremos que sea verdad. Por lo tanto, establecemos <span class="math inline">\(\mu\)</span> a <span class="math inline">\(0.10\)</span> y <span class="math inline">\(\tau\)</span> a <span class="math inline">\(0.01\)</span>. re. La elección de prior no tiene ningún efecto en el análisis bayesiano.</li>
</ol>
<p>8. El CLT nos dice que nuestra estimación del spread $ $ has normal distribution with expected value $ re $ and standard deviation $$ calculated in problem 6. Use the formulas we showed for the posterior distribution to calculate the expected value of the posterior distribution if we set $= 0 $ and $= 0.01 $.</p>
<p>9. Ahora calcule la desviación estándar de la distribución posterior.</p>
<p>10. Usando el hecho de que la distribución posterior es normal, cree un intervalo que tenga un 95% de probabilidad de ocurrir centrado en el valor esperado posterior. Tenga en cuenta que llamamos a estos intervalos creíbles.</p>
<p>11. Según este análisis, ¿cuál fue la probabilidad de que Trump gane Florida?</p>
<p>12. Ahora usa <code>sapply</code> función para cambiar la varianza anterior de <code>seq(0.05, 0.05, len = 100)</code> y observe cómo cambia la probabilidad haciendo un diagrama.</p>

</div>
<div id="election-forecasting" class="section level2">
<h2><span class="header-section-number">2.8</span> Estudio de caso: pronóstico de elecciones</h2>
<p>En una sección anterior, generamos estas tablas de datos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(dslabs)
polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-31&quot;</span> <span class="op">&amp;</span>
(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade))) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)
one_poll_per_pollster &lt;-<span class="st"> </span>polls <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(pollster) <span class="op">%&gt;%</span>
<span class="kw">filter</span>(enddate <span class="op">==</span><span class="st"> </span><span class="kw">max</span>(enddate)) <span class="op">%&gt;%</span>
<span class="kw">ungroup</span>()
results &lt;-<span class="st"> </span>one_poll_per_pollster <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread), <span class="dt">se =</span> <span class="kw">sd</span>(spread)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(spread))) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">start =</span> avg <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se, <span class="dt">end =</span> avg <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span><span class="op">*</span>se)</code></pre></div>
<p>A continuación, los utilizaremos para nuestro pronóstico.</p>
<div id="bayesian-approach" class="section level3">
<h3><span class="header-section-number">2.8.1</span> Enfoque bayesiano</h3>
<p>Los encuestadores tienden a hacer declaraciones probabilísticas sobre los resultados de las elecciones. Por ejemplo, “La posibilidad de que Obama gane el colegio electoral es del 91%” es una declaración probabilística sobre un parámetro que en secciones anteriores hemos señalado con <span class="math inline">\(d\)</span>. Mostramos que para las elecciones de 2016, FiveThirtyEight le dio a Clinton una probabilidad del 81.4% de ganar el voto popular. Para hacer esto, utilizaron el enfoque bayesiano que describimos.</p>
<p>Asumimos un modelo jerárquico similar al que hicimos para predecir el desempeño de un jugador de béisbol. Los libros de texto estadísticos escribirán el modelo así:</p>
<p><span class="math display">\[
\begin{aligned}
d &amp;\sim N(\mu,\tau^2)\mbox{ describes our best guess had we not seen any polling data}\\
\bar{X}\mid d &amp;\sim N(d,\sigma^2)\mbox{ describes randomness due to sampling and the pollster effect}
\end{aligned}
\]</span></p>
<p>Para nuestra mejor estimación, notamos que antes de que haya datos de encuestas disponibles, podemos usar fuentes de datos que no sean datos de encuestas. Un enfoque popular es utilizar lo que los encuestadores llaman <em>fundamentals</em>, que se basan en propiedades sobre la economía actual que históricamente parecen tener un efecto a favor o en contra de la parte titular. No usaremos estos aquí. En cambio, usaremos <span class="math inline">\(\mu = 0\)</span>, que se interpreta como un modelo que simplemente no proporciona información sobre quién ganará. Para la desviación estándar, usaremos datos históricos recientes que muestran que el ganador del voto popular tiene una extensión promedio de aproximadamente 3.5%. Por lo tanto, establecemos <span class="math inline">\(\tau = 0.035\)</span>.</p>
<p>Ahora podemos usar las fórmulas para la distribución posterior del parámetro <span class="math inline">\(d\)</span>: la probabilidad de <span class="math inline">\(d&gt;0\)</span> dados los datos de la encuesta observada:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="dv">0</span>
tau &lt;-<span class="st"> </span><span class="fl">0.035</span>
sigma &lt;-<span class="st"> </span>results<span class="op">$</span>se
Y &lt;-<span class="st"> </span>results<span class="op">$</span>avg
B &lt;-<span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>)
posterior_mean &lt;-<span class="st"> </span>B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>Y
posterior_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>))
posterior_mean
<span class="co">#&gt; [1] 0.0281</span>
posterior_se
<span class="co">#&gt; [1] 0.00615</span></code></pre></div>
<p>Para hacer una declaración de probabilidad, usamos el hecho de que la distribución posterior también es normal. Y tenemos un intervalo creíble de:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">posterior_mean <span class="op">+</span><span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="fl">1.96</span>, <span class="fl">1.96</span>)<span class="op">*</span>posterior_se
<span class="co">#&gt; [1] 0.0160 0.0401</span></code></pre></div>
<p>La probabilidad posterior $(d&gt; 0{X}) $ se puede calcular así:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">0</span>, posterior_mean, posterior_se)
<span class="co">#&gt; [1] 1</span></code></pre></div>
<p>Esto dice que estamos 100% seguros de que Clinton ganará el voto popular, lo que parece demasiado confiado. Además, no está de acuerdo con el 81.4% de FiveThirtyEight. ¿Qué explica esta diferencia?</p>
</div>
<div id="el-sesgo-general" class="section level3">
<h3><span class="header-section-number">2.8.2</span> El sesgo general</h3>
<p>Una vez finalizadas las elecciones, se puede observar la diferencia entre las predicciones de los encuestadores y el resultado real. Una observación importante que nuestro modelo no tiene en cuenta es que es común ver un sesgo general que afecta a muchos encuestadores de la misma manera haciendo correlacionar los datos observados. No hay una buena explicación para esto, pero lo observamos en los datos históricos: en una elección, el promedio de encuestas favorece a los demócratas en un 2%, luego en las siguientes elecciones favorecen a los republicanos en un 1%, luego en las próximas elecciones hay sin prejuicios, entonces en el siguiente los republicanos se ven favorecidos en un 3%, y así sucesivamente. En 2016, las encuestas fueron sesgadas a favor de los demócratas en un 1-2%.</p>
<p>Aunque sabemos que este término sesgo afecta nuestras encuestas, no tenemos forma de saber cuál es este sesgo hasta la noche de las elecciones. Por lo tanto, no podemos corregir nuestras encuestas en consecuencia. Lo que podemos hacer es incluir un término en nuestro modelo que explique esta variabilidad.</p>
</div>
<div id="representaciones-matematicas-de-modelos." class="section level3">
<h3><span class="header-section-number">2.8.3</span> Representaciones matemáticas de modelos.</h3>
<p>Supongamos que estamos recopilando datos de un encuestador y suponemos que no hay sesgo general. El encuestador recoge varias encuestas con un tamaño de muestra de <span class="math inline">\(N\)</span>, por lo que observamos varias mediciones de la propagación <span class="math inline">\(X_1,\dots, X_J\)</span>. La teoría nos dice que estas variables aleatorias tienen un valor esperado. <span class="math inline">\(d\)</span> y error estándar $ 2PS Comencemos usando el siguiente modelo para describir la variabilidad observada:</p>
<p><span class="math display">\[
X_j = d +\varepsilon_j.
\]</span> Usamos el índice <span class="math inline">\(j\)</span> para representar las diferentes encuestas y definimos <span class="math inline">\(\varepsilon_j\)</span> para ser una variable aleatoria que explica la variabilidad de encuesta a encuesta introducida por error de muestreo. Para hacer esto, asumimos que su promedio es 0 y el error estándar es $ 2 $. If $ re $ is 2.1 and the sample size for these polls is 2,000, we can simulate $ J = 6 $ puntos de datos de este modelo como este:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">3</span>)
J &lt;-<span class="st"> </span><span class="dv">6</span>
N &lt;-<span class="st"> </span><span class="dv">2000</span>
d &lt;-<span class="st"> </span>.<span class="dv">021</span>
p &lt;-<span class="st"> </span>(d <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="dv">2</span>
X &lt;-<span class="st"> </span>d <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J, <span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p)<span class="op">/</span><span class="st"> </span>N))</code></pre></div>
<p>Ahora supongamos que tenemos <span class="math inline">\(J=6\)</span> puntos de datos de <span class="math inline">\(I=5\)</span> diferentes encuestadores. Para representar esto, ahora necesitamos dos índices, uno para el encuestador y otro para las encuestas que toma cada encuestador. Usamos $ X_ {ij} $ with $ yo $ representing the pollster and $ j $ representing the $ j $ -th encuesta de ese encuestador. Si aplicamos el mismo modelo, escribimos:</p>
<p><span class="math display">\[
X_{i,j} = d +\varepsilon_{i,j}
\]</span></p>
<p>Para simular datos, ahora tenemos que recorrer los encuestadores:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">I &lt;-<span class="st"> </span><span class="dv">5</span>
J &lt;-<span class="st"> </span><span class="dv">6</span>
N &lt;-<span class="st"> </span><span class="dv">2000</span>
X &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span>I, <span class="cf">function</span>(i){
d <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J, <span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p)<span class="op">/</span><span class="st"> </span>N))
})</code></pre></div>
<p>Los datos simulados realmente no parecen capturar las características de los datos reales:</p>
<p><img src="libro_files/figure-html/simulated-data-without-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>El modelo anterior no tiene en cuenta la variabilidad de encuestador a encuestador. Para solucionar esto, agregamos un nuevo término para el efecto encuestador. Usaremos <span class="math inline">\(h_i\)</span> para representar el efecto de la casa de la <span class="math inline">\(i\)</span>-th encuestador. El modelo ahora se aumenta a:</p>
<p><span class="math display">\[
X_{i,j} = d + h_i +\varepsilon_{i,j}
\]</span></p>
<p>Para simular datos de un encuestador específico, ahora necesitamos dibujar un <span class="math inline">\(h_i\)</span> y luego agregue el <span class="math inline">\(\varepsilon\)</span> s. Así es como lo haríamos para un encuestador específico. Asumimos <span class="math inline">\(\sigma_h\)</span> es 0.025:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">I &lt;-<span class="st"> </span><span class="dv">5</span>
J &lt;-<span class="st"> </span><span class="dv">6</span>
N &lt;-<span class="st"> </span><span class="dv">2000</span>
d &lt;-<span class="st"> </span>.<span class="dv">021</span>
p &lt;-<span class="st"> </span>(d <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">/</span><span class="st"> </span><span class="dv">2</span>
h &lt;-<span class="st"> </span><span class="kw">rnorm</span>(I, <span class="dv">0</span>, <span class="fl">0.025</span>)
X &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span>I, <span class="cf">function</span>(i){
d <span class="op">+</span><span class="st"> </span>h[i] <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(J, <span class="dv">0</span>, <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p)<span class="op">/</span><span class="st"> </span>N))
})</code></pre></div>
<p>Los datos simulados ahora se parecen más a los datos reales:</p>
<p><img src="libro_files/figure-html/simulated-pollster-data-1.png" width="35%" style="display: block; margin: auto;" /></p>
<p>Tenga en cuenta que <span class="math inline">\(h_i\)</span> es común a todos los diferenciales observados de un encuestador específico. Diferentes encuestadores tienen un diferente <span class="math inline">\(h_i\)</span>, lo que explica por qué podemos ver los grupos de puntos desplazarse hacia arriba y hacia abajo de encuestador a encuestador.</p>
<p>Ahora, en el modelo anterior, asumimos que el efecto promedio de la casa es 0. Creemos que por cada encuestador sesgado a favor de nuestro partido, hay otro a favor del otro y asumimos que la desviación estándar es <span class="math inline">\(\sigma_h\)</span>. Pero históricamente vemos que cada elección tiene un sesgo general que afecta a todas las encuestas. Podemos observar esto con los datos de 2016, pero si recopilamos datos históricos, vemos que el promedio de las encuestas se pierde por más de lo que predicen modelos como el anterior. Para ver esto, tomaríamos el promedio de las encuestas para cada año electoral y lo compararíamos con el valor real. Si hiciéramos esto, veríamos una diferencia con una desviación estándar de entre 2-3%. Para incorporar esto en el modelo, podemos agregar otro término para explicar esta variabilidad: <span class="math display">\[
X_{i,j} = d + b + h_i +\varepsilon_{i,j}.
\]</span></p>
<p>Aquí <span class="math inline">\(b\)</span> es una variable aleatoria que explica la variabilidad de elección a elección. Esta variable aleatoria cambia de elección a elección, pero para cualquier elección dada, es la misma para todos los encuestadores y las encuestas dentro de la elección. Por eso no tiene índices. Esto implica que todas las variables aleatorias $ X_ {i,j} $ for an election year are correlated since they all have $ b $ en común.</p>
<p>Una forma de interpretar <span class="math inline">\(b\)</span> es como la diferencia entre el promedio de todas las encuestas de todos los encuestadores y el resultado real de la elección. Como no conocemos el resultado real hasta después de las elecciones, no podemos estimar <span class="math inline">\(b\)</span> hasta después de las elecciones. Sin embargo, podemos estimar <span class="math inline">\(b\)</span> de elecciones anteriores y estudiar la distribución de estos valores. Con base en este enfoque, asumimos que, a lo largo de los años electorales, <span class="math inline">\(b\)</span> tiene el valor esperado 0 y el error estándar es aproximadamente <span class="math inline">\(\sigma_b = 0.025\)</span>.</p>
<p>Una implicación de agregar este término al modelo es que la desviación estándar de $ X_ {i,j} $ is actually higher than what we earlier called $$, que combina la variabilidad del encuestador y la variabilidad de la muestra, y se estimó con:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(one_poll_per_pollster<span class="op">$</span>spread)
<span class="co">#&gt; [1] 0.0242</span></code></pre></div>
<p>Esta estimación no incluye la variabilidad introducida por <span class="math inline">\(b\)</span>. Tenga en cuenta que porque</p>
<p><span class="math display">\[
\bar{X} = d + b +\frac{1}{N}\sum_{i=1}^N X_i,
\]</span></p>
<p>la desviación estándar de <span class="math inline">\(\bar {X}\)</span> es:</p>
<p><span class="math display">\[
\sqrt{\sigma^2/N +\sigma_b^2}.
\]</span> Desde lo mismo <span class="math inline">\(b\)</span> está en cada medición, el promedio no reduce la variabilidad introducida por el <span class="math inline">\(b\)</span> término. Este es un punto importante: no importa cuántas encuestas realice, este sesgo no se reduce.</p>
<p>Si rehacemos el cálculo bayesiano teniendo en cuenta esta variabilidad, obtenemos un resultado mucho más cercano al de FiveThirtyEight:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="dv">0</span>
tau &lt;-<span class="st"> </span><span class="fl">0.035</span>
sigma &lt;-<span class="st"> </span><span class="kw">sqrt</span>(results<span class="op">$</span>se<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>.<span class="dv">025</span><span class="op">^</span><span class="dv">2</span>)
Y &lt;-<span class="st"> </span>results<span class="op">$</span>avg
B &lt;-<span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>)
posterior_mean &lt;-<span class="st"> </span>B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>Y
posterior_se &lt;-<span class="st"> </span><span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>))
<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">0</span>, posterior_mean, posterior_se)
<span class="co">#&gt; [1] 0.817</span></code></pre></div>
</div>
<div id="prediciendo-el-colegio-electoral" class="section level3">
<h3><span class="header-section-number">2.8.4</span> Prediciendo el colegio electoral</h3>
<p>Hasta ahora nos hemos centrado en el voto popular. Pero en los Estados Unidos, las elecciones no se deciden por el voto popular, sino por lo que se conoce como el colegio electoral. Cada estado obtiene una cantidad de votos electorales que depende, de una manera algo compleja, del tamaño de la población del estado. Aquí están los 5 principales estados clasificados por votos electorales en 2016.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">top_n</span>(<span class="dv">5</span>, electoral_votes)
<span class="co">#&gt;          state electoral_votes clinton trump others</span>
<span class="co">#&gt; 1   California              55    61.7  31.6    6.7</span>
<span class="co">#&gt; 2        Texas              38    43.2  52.2    4.5</span>
<span class="co">#&gt; 3      Florida              29    47.8  49.0    3.2</span>
<span class="co">#&gt; 4     New York              29    59.0  36.5    4.5</span>
<span class="co">#&gt; 5     Illinois              20    55.8  38.8    5.4</span>
<span class="co">#&gt; 6 Pennsylvania              20    47.9  48.6    3.6</span></code></pre></div>
<p>Con algunas excepciones menores que no discutimos, los votos electorales se ganan todo o nada. Por ejemplo, si gana California con solo 1 voto, aún obtiene los 55 votos electorales. Esto significa que al ganar algunos estados grandes por un amplio margen, pero al perder muchos estados pequeños por pequeños márgenes, puede ganar el voto popular y, sin embargo, perder el colegio electoral. Esto sucedió en 1876, 1888, 2000 y 2016. La idea detrás de esto es evitar que algunos estados grandes tengan el poder de dominar las elecciones presidenciales. Sin embargo, muchas personas en los Estados Unidos consideran que la universidad electoral es injusta y les gustaría verla abolida.</p>
<p>Ahora estamos listos para predecir el resultado del colegio electoral para 2016. Comenzamos agregando los resultados de una encuesta realizada durante la última semana antes de las elecciones. Utilizamos el <code>str_detect</code>, una función que presentamos más adelante en la Sección@ref (stringr), para eliminar las encuestas que no son para estados completos.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(state<span class="op">!=</span><span class="st">&quot;U.S.&quot;</span> <span class="op">&amp;</span>
<span class="op">!</span><span class="kw">str_detect</span>(state, <span class="st">&quot;CD&quot;</span>) <span class="op">&amp;</span>
enddate <span class="op">&gt;=</span><span class="st">&quot;2016-10-31&quot;</span> <span class="op">&amp;</span>
(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade))) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="kw">group_by</span>(state) <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread), <span class="dt">sd =</span> <span class="kw">sd</span>(spread), <span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.character</span>(state))</code></pre></div>
<p>Aquí están las cinco razas más cercanas según las encuestas:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">arrange</span>(<span class="kw">abs</span>(avg))
<span class="co">#&gt; # A tibble: 47 x 4</span>
<span class="co">#&gt;   state               avg     sd     n</span>
<span class="co">#&gt;   &lt;chr&gt;             &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;</span>
<span class="co">#&gt; 1 Florida         0.00356 0.0163     7</span>
<span class="co">#&gt; 2 North Carolina -0.00730 0.0306     9</span>
<span class="co">#&gt; 3 Ohio           -0.0104  0.0252     6</span>
<span class="co">#&gt; 4 Nevada          0.0169  0.0441     7</span>
<span class="co">#&gt; 5 Iowa           -0.0197  0.0437     3</span>
<span class="co">#&gt; # … with 42 more rows</span></code></pre></div>
<p>Ahora presentamos el comando <code>left_join</code> eso nos permitirá agregar fácilmente el número de votos electorales para cada estado del conjunto de datos <code>us_electoral_votes_2016</code>. Describiremos esta función en detalle en el capítulo Wrangling. Aquí, simplemente decimos que la función combina los dos conjuntos de datos para que la información del segundo argumento se agregue a la información del primero:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span><span class="kw">left_join</span>(results, results_us_election_<span class="dv">2016</span>, <span class="dt">by =</span> <span class="st">&quot;state&quot;</span>)</code></pre></div>
<p>Tenga en cuenta que algunos estados no tienen encuestas porque el ganador es bastante conocido:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="op">!</span>state <span class="op">%in%</span><span class="st"> </span>results<span class="op">$</span>state) <span class="op">%&gt;%</span>
<span class="kw">pull</span>(state)
<span class="co">#&gt; [1] &quot;Rhode Island&quot;         &quot;Alaska&quot;               &quot;Wyoming&quot;             </span>
<span class="co">#&gt; [4] &quot;District of Columbia&quot;</span></code></pre></div>
<p>No se realizaron encuestas en DC, Rhode Island, Alaska y Wyoming porque los demócratas seguramente ganarán en los primeros dos y los republicanos en los últimos dos.</p>
<p>Debido a que no podemos estimar la desviación estándar para los estados con una sola encuesta, la calcularemos como la mediana de las desviaciones estándar estimadas para los estados con más de una encuesta:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span>results <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">sd =</span> <span class="kw">ifelse</span>(<span class="kw">is.na</span>(sd), <span class="kw">median</span>(results<span class="op">$</span>sd, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>), sd))</code></pre></div>
<p>Para hacer argumentos probabilísticos, utilizaremos una simulación de Monte Carlo. Para cada estado, aplicamos el enfoque bayesiano para generar un día de elecciones <span class="math inline">\(d\)</span>. Podríamos construir los antecedentes de cada estado con base en la historia reciente. Sin embargo, para simplificar, asignamos un estado previo a cada estado que asume que no sabemos nada sobre lo que sucederá. Dado que de un año electoral a otro, los resultados de un estado específico no cambian tanto, asignaremos una desviación estándar del 2% o <span class="math inline">\(\tau=0.02\)</span>. Por ahora, asumiremos, incorrectamente, que los resultados de la encuesta de cada estado son independientes. El código para el cálculo bayesiano bajo estos supuestos se ve así:</p>
<pre><code>#&gt; # A tibble: 47 x 12
#&gt;   state     avg      sd     n electoral_votes clinton trump others
#&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;           &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
#&gt; 1 Alab… -0.149  2.53e-2     3               9    34.4  62.1    3.6
#&gt; 2 Ariz… -0.0326 2.70e-2     9              11    45.1  48.7    6.2
#&gt; 3 Arka… -0.151  9.90e-4     2               6    33.7  60.6    5.8
#&gt; 4 Cali…  0.260  3.87e-2     5              55    61.7  31.6    6.7
#&gt; 5 Colo…  0.0452 2.95e-2     7               9    48.2  43.3    8.6
#&gt; # … with 42 more rows, and 4 more variables: sigma &lt;dbl&gt;, B &lt;dbl&gt;,
#&gt; #   posterior_mean &lt;dbl&gt;, posterior_se &lt;dbl&gt;</code></pre>
<p>Las estimaciones basadas en posterior mueven las estimaciones hacia 0, aunque los estados con muchas encuestas están menos influenciados. Esto se espera ya que mientras más datos de encuestas recolectamos, más confiamos en esos resultados:</p>
<p><img src="libro_files/figure-html/posterior-versus-original-estimates-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Ahora repetimos esto 10.000 veces y generamos un resultado desde la parte posterior. En cada iteración, hacemos un seguimiento del número total de votos electorales para Clinton. Recuerde que Trump obtiene 270 menos los votos para Clinton. También tenga en cuenta que la razón por la que agregamos 7 en el código es para tener en cuenta Rhode Island y DC:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">10000</span>
mu &lt;-<span class="st"> </span><span class="dv">0</span>
tau &lt;-<span class="st"> </span><span class="fl">0.02</span>
clinton_EV &lt;-<span class="st"> </span><span class="kw">replicate</span>(B, {
results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">sigma =</span> sd<span class="op">/</span><span class="kw">sqrt</span>(n),
<span class="dt">B =</span> sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>),
<span class="dt">posterior_mean =</span> B <span class="op">*</span><span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>B) <span class="op">*</span><span class="st"> </span>avg,
<span class="dt">posterior_se =</span> <span class="kw">sqrt</span>(<span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>)),
<span class="dt">result =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(posterior_mean),
posterior_mean, posterior_se),
<span class="dt">clinton =</span> <span class="kw">ifelse</span>(result <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, electoral_votes, <span class="dv">0</span>)) <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">clinton =</span> <span class="kw">sum</span>(clinton)) <span class="op">%&gt;%</span>
<span class="kw">pull</span>(clinton) <span class="op">+</span><span class="st"> </span><span class="dv">7</span>
})
<span class="kw">mean</span>(clinton_EV <span class="op">&gt;</span><span class="st"> </span><span class="dv">269</span>)
<span class="co">#&gt; [1] 0.998</span></code></pre></div>
<p>Este modelo le da a Clinton más del 99% de posibilidades de ganar. <!--Here is a histogram of the Monte Carlo outcomes:
<img src="libro_files/figure-html/election-forecast-posterior-no-bias-1.png" width="70%" style="display: block; margin: auto;" />
--> El Consorcio Electoral de Princeton hizo una predicción similar. Ahora sabemos que estaba bastante apagado. ¿Que pasó?</p>
<p>El modelo anterior ignora el sesgo general y supone que los resultados de diferentes estados son independientes. Después de las elecciones, nos dimos cuenta de que el sesgo general en 2016 no era tan grande: estaba entre 1 y 2%. Pero debido a que la elección estuvo cerrada en varios estados grandes y estos estados tenían una gran cantidad de encuestas, los encuestadores que ignoraron el sesgo general subestimaron en gran medida el error estándar. Usando la notación que presentamos, asumieron que el error estándar era <span class="math inline">\(\sqrt {\sigma^2/N}\)</span> que con N grande es bastante más pequeño que la estimación más precisa $ $. FiveThirtyEight, which models the general bias in a rather sophisticated way, reported a closer result. We can simulate the results now with a bias term. For the state level, the general bias can be larger so we set it at $_b = 0.03 $:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">tau &lt;-<span class="st"> </span><span class="fl">0.02</span>
bias_sd &lt;-<span class="st"> </span><span class="fl">0.03</span>
clinton_EV_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">1000</span>, {
results <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">sigma =</span> <span class="kw">sqrt</span>(sd<span class="op">^</span><span class="dv">2</span><span class="op">/</span>n <span class="op">+</span><span class="st"> </span>bias_sd<span class="op">^</span><span class="dv">2</span>),
<span class="dt">B =</span> sigma<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="st"> </span>(sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>tau<span class="op">^</span><span class="dv">2</span>),
<span class="dt">posterior_mean =</span> B<span class="op">*</span>mu <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>B)<span class="op">*</span>avg,
<span class="dt">posterior_se =</span> <span class="kw">sqrt</span>( <span class="dv">1</span><span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>tau<span class="op">^</span><span class="dv">2</span>)),
<span class="dt">result =</span> <span class="kw">rnorm</span>(<span class="kw">length</span>(posterior_mean),
posterior_mean, posterior_se),
<span class="dt">clinton =</span> <span class="kw">ifelse</span>(result<span class="op">&gt;</span><span class="dv">0</span>, electoral_votes, <span class="dv">0</span>)) <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">clinton =</span> <span class="kw">sum</span>(clinton) <span class="op">+</span><span class="st"> </span><span class="dv">7</span>) <span class="op">%&gt;%</span>
<span class="kw">pull</span>(clinton)
})
<span class="kw">mean</span>(clinton_EV_<span class="dv">2</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">269</span>)
<span class="co">#&gt; [1] 0.848</span></code></pre></div>
<p>Esto nos da una estimación mucho más sensata. Al observar los resultados de la simulación, vemos cómo el término de sesgo agrega variabilidad a los resultados finales.</p>
<p><img src="libro_files/figure-html/comparison-forecast-with-and-without-bias-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>FiveThirtyEight incluye muchas otras características que no incluimos aquí. Una es que modelan la variabilidad con distribuciones que tienen altas probabilidades de eventos extremos en comparación con lo normal. Una forma de hacerlo es cambiando la distribución utilizada en la simulación de una distribución normal a una distribución t. FiveThirtyEight predijo una probabilidad del 71%.</p>
</div>
<div id="prevision" class="section level3">
<h3><span class="header-section-number">2.8.5</span> Previsión</h3>
<p>A los pronosticadores les gusta hacer predicciones mucho antes de las elecciones. Las predicciones se adaptan a medida que salen nuevas encuestas. Sin embargo, una pregunta importante que deben hacer los pronosticadores es: ¿qué tan informativas son las encuestas tomadas varias semanas antes de las elecciones sobre la elección real? Aquí estudiamos la variabilidad de los resultados de las encuestas a lo largo del tiempo.</p>
<p>Para asegurarnos de que la variabilidad que observamos no se deba a los efectos del encuestador, estudiemos los datos de un encuestador:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">one_pollster &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(pollster <span class="op">==</span><span class="st"> &quot;Ipsos&quot;</span> <span class="op">&amp;</span><span class="st"> </span>state <span class="op">==</span><span class="st"> &quot;U.S.&quot;</span>) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</code></pre></div>
<p>Como no hay efecto de encuestador, quizás el error estándar teórico coincida con la desviación estándar derivada de los datos. Calculamos ambos aquí:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">se &lt;-<span class="st"> </span>one_pollster <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">empirical =</span> <span class="kw">sd</span>(spread),
<span class="dt">theoretical =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>(spread) <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(spread))<span class="op">/</span>
<span class="kw">min</span>(samplesize)))
se
<span class="co">#&gt;   empirical theoretical</span>
<span class="co">#&gt; 1    0.0403      0.0326</span></code></pre></div>
<p>Pero la desviación estándar empírica es más alta que la estimación teórica más alta posible. Además, los datos difundidos no parecen normales, ya que la teoría predeciría:</p>
<p><img src="libro_files/figure-html/time-trend-variability-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Los modelos que hemos descrito incluyen la variabilidad de encuestador a encuestador y el error de muestreo. Pero esta gráfica es para un encuestador y la variabilidad que vemos ciertamente no se explica por el error de muestreo. ¿De dónde viene la variabilidad extra? Las siguientes tramas muestran un fuerte argumento de que proviene de fluctuaciones de tiempo no explicadas por la teoría que asume <span class="math inline">\(p\)</span> está arreglado:</p>
<p><img src="libro_files/figure-html/time-trend-estimate-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Algunos de los picos y valles que vemos coinciden con eventos como las convenciones del partido, que tienden a dar un impulso al candidato. Podemos ver que los picos y valles son consistentes en varios encuestadores:</p>
<p><img src="libro_files/figure-html/time-trend-estimate-several-pollsters-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Esto implica que, si vamos a pronosticar, nuestro modelo debe incluir un término para contabilizar el efecto temporal. Necesitamos escribir un modelo que incluya un término de sesgo para el tiempo:</p>
<p><span class="math display">\[
Y_{i,j,t} = d + b + h_j + b_t +\varepsilon_{i,j,t}
\]</span></p>
<p>La desviación estándar de <span class="math inline">\(b_t\)</span> dependería de <span class="math inline">\(t\)</span> ya que cuanto más nos acercamos al día de las elecciones, más cerca de 0 debería estar este término de sesgo.</p>
<p>Los encuestadores también intentan estimar las tendencias de estos datos e incorporarlos en sus predicciones. Podemos modelar la tendencia temporal con una función <span class="math inline">\(f(t)\)</span> y reescribe el modelo así: Las líneas azules en las parcelas de arriba:</p>
<p><span class="math display">\[
Y_{i,j,t} = d + b + h_j + b_t + f(t) +\varepsilon_{i,jt,}
\]</span></p>
<p>Usualmente vemos el estimado <span class="math inline">\(f(t)\)</span> no por la diferencia, sino por los porcentajes reales para cada candidato como este:</p>
<p><img src="libro_files/figure-html/trend-estimate-for-all-pollsters-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Una vez que se selecciona un modelo como el anterior, podemos usar datos históricos y actuales para estimar todos los parámetros necesarios para hacer predicciones. Existe una variedad de métodos para estimar tendencias. <span class="math inline">\(f(t)\)</span> que discutimos en la parte de Machine Learning.</p>
</div>
</div>
<div id="ejercicios-6" class="section level2">
<h2><span class="header-section-number">2.9</span> Ejercicios</h2>
<p>1. Crea esta tabla:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(dslabs)
<span class="kw">data</span>(<span class="st">&quot;polls_us_election_2016&quot;</span>)
polls &lt;-<span class="st"> </span>polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(state <span class="op">!=</span><span class="st"> &quot;U.S.&quot;</span> <span class="op">&amp;</span><span class="st"> </span>enddate <span class="op">&gt;=</span><span class="st"> &quot;2016-10-31&quot;</span>) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>)</code></pre></div>
<p>Ahora, para cada encuesta, use el CLT para crear un intervalo de confianza del 95% para la propagación informada por cada encuesta. Llame al objeto resultante cis con columnas inferior y superior para los límites de los intervalos de confianza. Utilizar el <code>select</code> función para mantener las columnas <code>state, startdate, end date, pollster, grade, spread, lower, upper</code>.</p>
<p>2. Puede agregar el resultado final a la <code>cis</code> tabla que acaba de crear utilizando el <code>right_join</code> funciona así:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">add &lt;-<span class="st"> </span>results_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">actual_spread =</span> clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="kw">select</span>(state, actual_spread)
cis &lt;-<span class="st"> </span>cis <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.character</span>(state)) <span class="op">%&gt;%</span>
<span class="kw">left_join</span>(add, <span class="dt">by =</span> <span class="st">&quot;state&quot;</span>)</code></pre></div>
<p>Ahora determine con qué frecuencia el intervalo de confianza del 95% incluye el resultado real.</p>
<p>3. Repita esto, pero muestre la proporción de golpes para cada encuestador. Mostrar solo encuestadores con más de 5 encuestas y ordenarlos de mejor a peor. Muestre el número de encuestas realizadas por cada encuestador y la calificación FiveThirtyEight de cada encuestador. Sugerencia: uso <code>n=n(), grade = grade[1]</code> en la convocatoria para resumir.</p>
<p>4. Repita el ejercicio 3, pero en lugar de encuestador, estratifique por estado. Tenga en cuenta que aquí no podemos mostrar calificaciones.</p>
<p>5. Haz un diagrama de barras basado en el resultado del ejercicio 4. Usa <code>coord_flip</code>.</p>
<p>6. Agregue dos columnas a la <code>cis</code> tabla calculando, para cada encuesta, la diferencia entre el margen previsto y el margen real, y define una columna <code>hit</code> eso es cierto si los signos son los mismos. Sugerencia: use la función <code>sign</code>. Llamar al objeto <code>resids</code>.</p>
<p>7. Cree una gráfica como en el ejercicio 5, pero por la proporción de veces que el signo de la propagación estuvo de acuerdo.</p>
<p>8. En el ejercicio 7, vemos que para la mayoría de los estados las encuestas acertaron el 100% del tiempo. Solo en 9 estados las encuestas se perdieron más del 25% del tiempo. En particular, observe que en Wisconsin todas las encuestas se equivocaron. En Pensilvania y Michigan, más del 90% de las encuestas tenían los signos incorrectos. Haz un histograma de los errores. ¿Cuál es la mediana de estos errores?</p>
<p>9. Vemos que a nivel estatal, el error medio fue del 3% a favor de Clinton. La distribución no está centrada en 0, sino en 0.03. Este es el sesgo general que describimos en la sección anterior. Cree un diagrama de caja para ver si el sesgo fue general para todos los estados o si afectó a algunos estados de manera diferente. Utilizar <code>filter(grade %in% c(&quot;A+&quot;,&quot;A&quot;,&quot;A-&quot;,&quot;B+&quot;) | is.na(grade)))</code> incluir solo encuestadores con altas calificaciones.</p>
<p>10. Algunos de estos estados solo tienen unas pocas encuestas. Repita el ejercicio 9, pero solo incluya estados con 5 encuestas buenas o más. Sugerencia: uso <code>group_by</code>, <code>filter</code> luego <code>ungroup</code>. Verá que el Oeste (Washington, Nuevo México, California) subestimó el desempeño de Hillary, mientras que el Medio Oeste (Michigan, Pensilvania, Wisconsin, Ohio, Missouri) lo sobrestimó. En nuestra simulación, no modelamos este comportamiento ya que agregamos un sesgo general, en lugar de un sesgo regional. Tenga en cuenta que algunos encuestadores ahora pueden modelar la correlación entre estados similares y estimar esta correlación a partir de datos históricos. Para obtener más información sobre esto, puede aprender sobre efectos aleatorios y modelos mixtos.</p>

</div>
<div id="t-dist" class="section level2">
<h2><span class="header-section-number">2.10</span> La distribución t</h2>
<p>Arriba utilizamos el CLT con un tamaño de muestra de 15. Porque estamos estimando un segundo parámetro <span class="math inline">\(\sigma\)</span>, se introduce una mayor variabilidad en nuestro intervalo de confianza, lo que da como resultado intervalos que son demasiado pequeños. Para tamaños de muestra muy grandes, esta variabilidad adicional es insignificante, pero, en general, para valores menores de 30 debemos ser cautelosos al usar el CLT.</p>
<p>Sin embargo, si se sabe que los datos en la urna siguen una distribución normal, entonces tenemos una teoría matemática que nos dice cuánto más necesitamos hacer los intervalos para dar cuenta de la estimación de <span class="math inline">\(\sigma\)</span>. Usando esta teoría, podemos construir intervalos de confianza para cualquier <span class="math inline">\(N\)</span>. Pero, de nuevo, esto funciona solo si ** se sabe que los datos en la urna siguen una distribución normal **. Entonces, para los datos 0, 1 de nuestro modelo de urna anterior, esta teoría definitivamente no se aplica.</p>
<p>La estadística sobre los intervalos de confianza para <span class="math inline">\(d\)</span> se basan es</p>
<p><span class="math display">\[
Z =\frac{\bar{X} - d}{\sigma/\sqrt{N}}
\]</span></p>
<p>CLT nos dice que Z se distribuye aproximadamente normalmente con el valor esperado 0 y el error estándar 1. Pero en la práctica no sabemos <span class="math inline">\(\sigma\)</span> entonces usamos:</p>
<p><span class="math display">\[
Z =\frac{\bar{X} - d}{s/\sqrt{N}}
\]</span></p>
<p>Mediante la sustitución <span class="math inline">\(\sigma\)</span> con <span class="math inline">\(s\)</span> introducimos cierta variabilidad. La teoría nos dice que <span class="math inline">\(Z\)</span> sigue una distribución t con <span class="math inline">\(N-1\)</span> <em>grados de libertad</em>. Los grados de libertad es un parámetro que controla la variabilidad a través de colas más gruesas:</p>
<p><img src="libro_files/figure-html/t-distribution-examples-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Si estamos dispuestos a asumir que los datos del efecto encuestador se distribuyen normalmente, en función de los datos de la muestra <span class="math inline">\(X_1,\dots, X_N\)</span>,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">one_poll_per_pollster <span class="op">%&gt;%</span>
<span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">sample=</span>spread)) <span class="op">+</span><span class="st"> </span><span class="kw">stat_qq</span>()</code></pre></div>
<p><img src="libro_files/figure-html/poll-spread-qq-1.png" width="70%" style="display: block; margin: auto;" /> luego <span class="math inline">\(Z\)</span> sigue una distribución t con <span class="math inline">\(N-1\)</span> grados de libertad. Entonces quizás un mejor intervalo de confianza para <span class="math inline">\(d\)</span> es:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">z &lt;-<span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="kw">nrow</span>(one_poll_per_pollster)<span class="op">-</span><span class="dv">1</span>)
one_poll_per_pollster <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">avg =</span> <span class="kw">mean</span>(spread), <span class="dt">moe =</span> z<span class="op">*</span><span class="kw">sd</span>(spread)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(spread))) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">start =</span> avg <span class="op">-</span><span class="st"> </span>moe, <span class="dt">end =</span> avg <span class="op">+</span><span class="st"> </span>moe)
<span class="co">#&gt; # A tibble: 1 x 4</span>
<span class="co">#&gt;      avg    moe  start    end</span>
<span class="co">#&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span>
<span class="co">#&gt; 1 0.0290 0.0134 0.0156 0.0424</span></code></pre></div>
<p>Un poco más grande que el que usa normal es</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">14</span>)
<span class="co">#&gt; [1] 2.14</span></code></pre></div>
<p>es mayor que</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(<span class="fl">0.975</span>)
<span class="co">#&gt; [1] 1.96</span></code></pre></div>
<p>La distribución t también se puede usar para modelar errores en desviaciones más grandes que son más probables que con la distribución normal, como se ve en las densidades que vimos anteriormente. Fivethirtyeight utiliza la distribución t para generar errores que modelen mejor las desviaciones que vemos en los datos electorales. Por ejemplo, en Wisconsin, el promedio de seis encuestas fue del 7% a favor de Clinton con una desviación estándar del 1%, pero Trump ganó un 0,7%. Incluso después de tener en cuenta el sesgo general, este 7,7% residual está más en línea con los datos distribuidos en t que la distribución normal.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;polls_us_election_2016&quot;</span>)
polls_us_election_<span class="dv">2016</span> <span class="op">%&gt;%</span>
<span class="kw">filter</span>(state <span class="op">==</span><span class="st">&quot;Wisconsin&quot;</span> <span class="op">&amp;</span>
enddate <span class="op">&gt;=</span><span class="st">&quot;2016-10-31&quot;</span> <span class="op">&amp;</span>
(grade <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A+&quot;</span>,<span class="st">&quot;A&quot;</span>,<span class="st">&quot;A-&quot;</span>,<span class="st">&quot;B+&quot;</span>) <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(grade))) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">spread =</span> rawpoll_clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>rawpoll_trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">state =</span> <span class="kw">as.character</span>(state)) <span class="op">%&gt;%</span>
<span class="kw">left_join</span>(results_us_election_<span class="dv">2016</span>, <span class="dt">by =</span> <span class="st">&quot;state&quot;</span>) <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">actual =</span> clinton<span class="op">/</span><span class="dv">100</span> <span class="op">-</span><span class="st"> </span>trump<span class="op">/</span><span class="dv">100</span>) <span class="op">%&gt;%</span>
<span class="kw">summarize</span>(<span class="dt">actual =</span> <span class="kw">first</span>(actual), <span class="dt">avg =</span> <span class="kw">mean</span>(spread),
<span class="dt">sd =</span> <span class="kw">sd</span>(spread), <span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span>
<span class="kw">select</span>(actual, avg, sd, n)
<span class="co">#&gt;   actual    avg     sd n</span>
<span class="co">#&gt; 1 -0.007 0.0711 0.0104 6</span></code></pre></div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["libro.pdf", "libro.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
